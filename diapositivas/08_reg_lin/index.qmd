---
title: Analítica de los Negocios
author: Carlos Cardona Andrade
subtitle: Intro a la Regresión Lineal
execute:
  freeze: auto
  echo: true
  fig-width: 6
  fig-height: 5
format:
  revealjs: 
   theme: ../slides.scss
   header-includes: |
      <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" rel="stylesheet"/>
   slide-number: true
   show-slide-number: all
   transition: fade
   progress: true
   multiplex: false
   scrollable: false
   preview-links: false
   hide-inactive-cursor: true
   highlight-style: printing
   pause: true
---


## Plan para hoy

1. [Correlación](#corr)

2. [Regresión Lineal Simple](#lm)

3. [Regresión Lineal Múltiple](#multiple)

# Correlación {#corr}


## US Total Gross vs Opening Gross {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

library(tidyverse)
library(readxl)
library(janitor)
hollywood <- read_excel("C:/Users/ccard/Downloads/KEL702-XLS-ENG.xls", sheet = "Exhibit 1")
hollywood <- hollywood %>%
  clean_names()
hollywood <- hollywood %>% rename(us_gross = total_u_s_gross)
hollywood <- hollywood %>% rename(non_us_gross = total_non_u_s_gross)

```

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| code-fold: true

ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
    geom_point() +
    labs(
        x = "Opening Gross (in millions)",
        y = "US Total Gross (in millions)"
    ) +
    theme_minimal()

```

## La correlación en R {.medium}

- Podemos utilizar un diagrama de dispersión para realizar un primer análisis de la relación entre dos variables

- El coeficiente de correlación (lineal) es utilizado para medir la fuerza de la asociación (lineal) entre dos variables

- La correlación entre el recaudo en US y el recaudo el primer fin de semana:

```{r}
#| echo: true
cor(hollywood$us_gross,hollywood$opening_gross)
```


## Función `corrplot` {.medium}

```{r}
#| echo: true
#| eval: false
#| fig-align: center

# RECUERDEN INSTALAR EL PAQUETE PRIMERO!!!
# install.packages("corrplot")

# Cargamos el paquete
library(corrplot)

# Creemos una base de datos temporal sólo con estas 4 variables
hollywood_sub <- hollywood %>% select( us_gross, opening_gross, non_us_gross, budget) 

# Creemos la matriz de correlaciones
corrplot(cor(hollywood_sub ),
         method = "number",
         type = "upper")

```



## Función `corrplot` {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: center

# RECUERDEN INSTALARLA PRIMERO!!!
# install.packages("corrplot)

# Cargamos el paquete
library(corrplot)

# Creemos una base de datos temporal sólo con estas 4 variables
hollywood_sub <- hollywood %>% select( us_gross, opening_gross, non_us_gross, budget) 

# Creemos la matriz de correlaciones
corrplot(cor(hollywood_sub ),
         method = "number",
         type = "upper")

```



## La correlación no es suficiente {.medium}


```{r}
#| echo: false
#| eval: true
#| fig-align: center

library(datasauRus)
library(patchwork)

dino <- datasaurus_dozen %>%
  filter(dataset == "dino")

star <- datasaurus_dozen %>%
  filter(dataset == "star")

hlines <- datasaurus_dozen %>%
  filter(dataset == "h_lines")

dino %>%
  summarize(
      mean_x    = mean(x),
      mean_y    = mean(y),
      std_dev_x = sd(x),
      std_dev_y = sd(y),
      corr_x_y  = cor(x, y)
  )



```



```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 7
#| fig-height: 3.5

ggplot(dino, aes(x=x, y=y))+
  geom_point(color = "darkred") + theme_minimal()
```




## La correlación no es suficiente {.medium}


```{r}
#| echo: false
#| eval: true
#| fig-align: center
star %>%
  summarize(
      mean_x    = mean(x),
      mean_y    = mean(y),
      std_dev_x = sd(x),
      std_dev_y = sd(y),
      corr_x_y  = cor(x, y)
  )
```

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 7
#| fig-height: 3.5
ggplot(star, aes(x=x, y=y))+
  geom_point(color = "navy") + theme_minimal()

```


## La correlación no es suficiente {.medium}


```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 7
#| fig-height: 3.5
hlines %>%
  summarize(
      mean_x    = mean(x),
      mean_y    = mean(y),
      std_dev_x = sd(x),
      std_dev_y = sd(y),
      corr_x_y  = cor(x, y)
  )
```

```{r}
#| echo: false
#| eval: true
#| fig-align: center

ggplot(hlines, aes(x=x, y=y))+
  geom_point(color = "orange") + theme_minimal()

```



# Regresión Lineal Simple {#lm}

     
## Partes esenciales de una regresión {.medium}

::: columns
::: {.column width="50%"}
### Y  {.text-orange-gold .center}

- Variable dependiente

- Variable resultado

- Básicamente lo que queremos predecir o explicar

:::

::: {.column .fragment width="50%"}

### X  {.text-orange-gold .center}

- Variable explicativa

- Predictor

- Variable independiente

- Lo que usamos para predecir o explicar Y
:::
:::


## ¿Por qué una regresión? {.medium}

Usualmente ajustamos a una línea por dos razones:

### Predicción

- Predecir el futuro

- Nos enfocamos en Y

- Netflix tratando de predecir la siguiente serie que veremos

### Explicación

- Explicar el efecto de X en Y

- Nos enfocamos en X

- Netflix evaluando el efecto de la hora del día en la selección de una serie


## ¿Cómo? {.medium}

1. Graficar X y Y

2. Dibujar una recta que se aproxime a la relación observada (ojalá funcione para datos que no están en la muestra)

3. Estimar los números que componen esa recta

4. Interpretar esos números

```{r}
#| echo: false
library(tidyverse)
library(patchwork)
library(broom)
library(knitr)
galletas <- tibble(felicidad = c(0.5, 2, 1, 2.5, 3, 1.5, 2, 2.5, 2, 3),
                  galletas = 1:10)

galletas_datos <- galletas
modelo_galletas <- lm(felicidad ~ galletas, data = galletas_datos)
predict_galletas <- augment(modelo_galletas)
```



## Galletas y Felicidad {.medium}

::: {.tbl-classic .tbl-larger .center-text}


```{r}
#| echo: false
#| eval: true

galletas |> 
  knitr::kable(format = "html") |> 
  kableExtra::kable_styling(font_size = 30) # Adjust the font size as needed
```

:::

## 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4



base_cookies <- ggplot(predict_galletas, aes(x = galletas, y = felicidad)) +
  geom_point(size = 3) +
  coord_cartesian(xlim = c(0, 10), ylim = c(0, 3)) +
  scale_x_continuous(breaks = 0:10) +
  labs(x = "Galletas consumidas", y = "Nivel de Felicidad") +
  theme_minimal(base_size = 14) +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold"))

base_cookies
```




## 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

base_cookies +
  geom_smooth(method = lm, color = "#0074D9", formula = y ~ splines::bs(x, 7), se = FALSE)
```

## 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

base_cookies +
  geom_smooth(method = "loess", color = "#0074D9", se = FALSE)
```

##

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

base_cookies +
  geom_smooth(method = "lm", color = "#0074D9", se = FALSE)
```

##

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

galletas_con_residuo <- base_cookies +
  geom_smooth(method = "lm", color = "#0074D9", se = FALSE) +
  geom_segment(aes(xend = galletas, yend = .fitted), color = "#FF851B", size = 1)

galletas_con_residuo
```

## 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

galletas_solo_residuo <- ggplot(predict_galletas, aes(x = galletas, y = .resid)) +
  geom_hline(yintercept = 0, color = "#B10DC9", size = 1) +
  geom_point(size = 3) +
  geom_segment(aes(xend = galletas, yend = 0), color = "#FF851B", size = 1) +
  coord_cartesian(xlim = c(0, 10), ylim = c(-1.5, 1.5)) +
  scale_x_continuous(breaks = 0:10) +
  labs(x = "Galletas consumidas", y = "Distancia a la línea") +
  theme_minimal(base_size = 14) +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold"))

galletas_solo_residuo
```

##


```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

(galletas_con_residuo + labs(title = "Galletas y Felicidad")) + 
  (galletas_solo_residuo + labs(title = "Residuos"))
```

## Pendiente de una recta {.medium}

$$
y = mx + b
$$

::: {.tbl-classic .tbl-larger .center-text}


|     |                                          |
|:---:|:----------------------------------------:|
| $y$ |                Un número                 |
| $x$ |                Un número                 |
| $m$ | La pendiente $\frac{\Delta y}{\Delta x}$ |
| $b$ |          El intercepto con $y$           |

:::

## Pendiente de una recta {.medium}

::: columns
::: {.column width="50%"}
$$
y = 2x - 1
$$

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 4.8
#| fig-height: 3.5

ggplot(data = tibble(x = 0:5), aes(x = x)) +
  stat_function(fun = function(x) 2 * x - 1, 
                color = "#BF3984", size = 1.5) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = 0:5) +
  scale_y_continuous(breaks = -1:9) +
  theme(panel.grid.minor = element_blank())
```

:::



::: {.column .fragment width="50%"}
$$
y = -0.5x + 6
$$

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 4.8
#| fig-height: 3.5

ggplot(data = tibble(x = 0:14), aes(x = x)) +
  stat_function(fun = function(x) -0.5 * x + 6, 
                color = "#BF3984", size = 1.5) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = 0:14) +
  scale_y_continuous(breaks = -1:9) +
  theme(panel.grid.minor = element_blank())
```

:::
:::

## Regresión lineal simple {.medium}

$$
Y = \beta_0 + \beta_1 X + \varepsilon
$$

-   $\beta_1$: la pendiente verdadera de la relación entre $X$ y $Y$

-   $\beta_0$: el intercepto verdadero de la relación entre $X$ y $Y$

-   $\varepsilon$: el error

## Regresión lineal simple {.medium}

$$
\hat{Y} = \hat{\beta_0} + \hat{\beta_1} X 
$$

-   $\hat{\beta_1}$: la pendiente estimado de la relación entre $X$ y $Y$

-   $\hat{\beta_0}$: el intercepto estimado de la relación entre $X$ y $Y$

-   No hay error!!!

## Modelo de Regresión {.medium}

::: columns
::: {.column width="40%"}
$$  
  \begin{aligned}
Y &= \color{#0074D9}{\text{Modelo}} + \color{#FF851B}{\text{Error}} \\
  &= \color{#0074D9}{f(X)} + \color{#FF851B}{\varepsilon}
\end{aligned}
$$
:::

::: {.column width="60%"}
```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| out-width: "100%"


galletas_con_residuo
```
:::
:::

## Residuos {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| out-width: "100%"


galletas_con_residuo

```

$$
\text{Residuo} = \text{Observado} - \text{Predicho} = y - \hat{y}
$$

## La línea de los mínimos cuadrados {.medium}

-   El residuo para la observación $i^{th}$ es:

$$e_i= \text{Observado} - \text{Predicho}=y_i - \hat{y_i}$$ - La **suma de los residuos al cuadrado** es:

$$e_1^2+e_2^2+e_3^2+..+e_n^2$$

-   La **línea de los mínimos cuadrados** es la que minimiza la suma de los residuos al cuadrado

## 

```{r}
#| eval: true
#| echo: false
#| fig-align: "center"
#| out-width: "100%"
knitr::include_graphics("img/meme.png")

```

## Construyendo modelos en R {.medium}

-   La sintáxis para los resultados del modelo es:

```{r}
#| eval: false
#| echo: true

name_of_model <- lm(Y ~ X, data = DATA)

summary(name_of_model)  # Para ver los detalles del modelo
```

::: fragment
-   Otras opciones para evaluar el modelo son:

```{r}
#| eval: false
#| echo: true

library(broom)

# Convierte los resultados del modelo a un data frame para graficar
tidy(name_of_model)

# Convierte los parámetros que evalúan el modelo a un data frame
glance(name_of_model)
```
:::

## Modelando Galletas y Felicidad {.medium}

::: columns
::: {.column width="40%"}
$$\widehat{Felicidad}=\hat{\beta_0}+\hat{\beta_1}\times Galletas$$

```{r}
#| echo: true
#| eval: true
modelo_felicidad <- 
  lm(felicidad ~ galletas,
     data = galletas_datos)
```
:::

::: {.column width="60%"}
```{r}
#| echo: false
#| label: cookies-happiness-again
#| results: hide


base_cookies +
  geom_smooth(method = "lm", color = "#0074D9") +
  coord_cartesian(xlim = c(0, 10), ylim = c(0, 4))
```
:::
:::

## Modelando Galletas y Felicidad {.medium}

Podemos ver los coeficientes, error estándar, p-value e IC:

```{r}
#| echo: true
tidy(modelo_felicidad, conf.int = TRUE)
```

::: fragment
Para ver aspectos evaluando el ajuste del modelo:
```{r}
#| echo: true
glance(modelo_felicidad)
```
:::

## Traduciendo los resultados a matemáticas {.medium}

::: columns
::: {.column width="40%"}
```{r}
#| echo: false
tidy(modelo_felicidad, conf.int = TRUE) |> 
  select(term, estimate)
```

$$
\begin{aligned}
&\widehat{Felicidad} = \\ 
&\hat{\beta_0}+\hat{\beta_1}\times Galletas
\end{aligned}
$$

$$
\begin{aligned}
&\widehat{Felicidad} = \\ 
&1.1 + 0.16 \times Galletas
\end{aligned}
$$
:::

::: {.column width="60%"}
```{r}
#| echo: false
base_cookies +
  geom_smooth(method = "lm", color = "#0074D9") +
  coord_cartesian(xlim = c(0, 10), ylim = c(0, 4))
```
:::
:::

## Interpretación de los coeficientes {.medium}

Un incremento en una unidad de $X$ está *asociado* con un incremento (o reducción) promedio de $\beta_1$ unidades en $Y$

$$\widehat{Felicidad}=\hat{\beta_0}+\hat{\beta_1}\times Galletas$$

$$\widehat{Felicidad} = 1.1 + 0.16 \times Galletas$$

:::{.incremental}

- En *promedio*, una galleta adicional está asociado a aumento en la felicidad de 0.16 unidades

- Si no hay consumo de galletas, esperamos que el puntaje de felicidad sea 1.1 unidades
:::


## ¿Es el intercepto importante? {.medium}

- La interpretación del intercepto es importante si en el contexto de los datos:

  1. La variable independiente puede tomar valores iguales o cercanos a cero
  
  2. La variable independiente tiene valores cercanos a cero en los datos observados
  
:::{.incremental}
  
- En caso contrario, el intercepto no tiene ninguna interpretación práctica

- Veremos más ejemplos sobre esto más adelante...
:::


## Volvamos a Hollywood Rules  {.medium}

- Según la sabiduría popular en Hollywood, el recaudo durante el primer fin de semana es un fuerte predictor del éxito comercial de una película
- Grafiquemos la relación entre el recaudo en Estados Unidos y el recaudo en el primer fin de semana para evaluar esta creencia:




## Volvamos a Hollywood Rules  {.medium}


```{r}
#| echo: false
#| eval: true
#| fig-align: center

ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
    geom_point() +
    labs(
        x = "Opening Gross (in millions)",
        y = "US Total Gross (in millions)"
    ) +
    theme_minimal()

```



## Volvamos a Hollywood Rules  {.medium}

```{r}
#| echo: true
#| eval: true
hollywood_model <- lm(us_gross ~ opening_gross, data=hollywood)
tidy(hollywood_model, conf.int = TRUE)

```

:::{.fragment}

Entonces nuestro modelo lineal es:

$$\widehat{\text{US Total Gross}} = 5,108,220 + 3.12 \times \text{Opening Gross}$$

:::

:::{.fragment}
¿Cuál es la interpretación de $\hat{\beta_1}$ en este caso?¿Y de $\hat{\beta_0}$?
:::



## ¿ Cómo graficar la línea de regresión? {.medium}

`geom_smooth(method="lm")`es la función dentro de ggplot para gráficar la línea de regresión y su respectivo intervalo de confianza.


```{r}
#| echo: true
#| eval: false
#| fig-width: 8
#| fig-height: 4
#| fig-align: center
#| code-line-numbers: "3"
ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
    geom_point() +
    geom_smooth(method="lm") +
    labs(
        x = "Opening Gross (in millions)",
        y = "US Total Gross (in millions)"
    ) +
    theme_minimal()

```


## ¿ Cómo graficar la línea de regresión? {.medium}


```{r}
#| echo: false
#| eval: true
#| fig-width: 8
#| fig-height: 4
#| fig-align: center

ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
    geom_point() +
    geom_smooth(method="lm") +
    labs(
        x = "Opening Gross (in millions)",
        y = "US Total Gross (in millions)"
    ) +
    theme_minimal()

```


## Predicción  {.medium}

Según nuestro modelo, ¿cuál sería el recaudo en US de una película cuyo recaudo en el primer fin de semana fue de \$50,000,000?



$$  
  \begin{aligned}
\widehat{\text{US Gross}} &= 5,108,220 + 3.12 \times \text{Opening Gross} \\
  &= 5,108,220 + 3.12 \times \color{red}{50,000,000} \\
  &= 161,108,220
\end{aligned}
$$

## Predicción con R {.medium}

El comando `predict()` nos permite predecir $\widehat{\text{US Gross}}$ para uno o varios valores:



```{r}
#| echo: true
#| eval: true

# Creamos los valores para los cuales queremos predecir
valores_opening <- data.frame(opening_gross = c(20000000,40000000,50000000))


# Predice los valores con los coeficientes estimados
# en hollywood_model
predict(hollywood_model, newdata = valores_opening)

```


## Predicción  {.medium}


```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 8

model <- lm(us_gross ~ opening_gross , data = hollywood)

# Predict the corresponding y value when x = 50
predicted_y <- predict(model, newdata = data.frame(opening_gross = 50 * 1000000))

# Plot
ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
  geom_point() +
  geom_smooth(method = "lm") +
  geom_vline(xintercept = 50, linetype = "dashed", color = "blue") +   # Dashed vertical line at x = 50
  geom_hline(yintercept = predicted_y/ 1000000, linetype = "dashed", color = "blue") + # Dashed horizontal line at predicted y
  geom_point(aes(x = 50, y = predicted_y/ 1000000), color = "red", size = 3) + # Point at (50, predicted_y)
  labs(
    x = "Opening Gross (in millions)",
    y = "US Total Gross (in millions)"
  ) +
  theme_minimal()
```





## ¿Es posible la extrapolación? {.medium}

Extrapolar es tratar de predecir Y fuera del rango de valores de X. Es posible pero no aconsejable.

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 8
# Predict the corresponding y value when x = 80
predicted_y <- predict(model, newdata = data.frame(opening_gross = 80 * 1000000))

# Plot
ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
    geom_point() +
    geom_smooth(method = "lm") +
    geom_vline(xintercept = 80, linetype = "dashed", color = "blue") +   # Dashed vertical line at x = 80
    geom_hline(yintercept = predicted_y/ 1000000, linetype = "dashed", color = "blue") + # Dashed horizontal line at predicted y
    geom_point(aes(x = 80, y = predicted_y/ 1000000), color = "red", size = 3) + # Point at (80, predicted_y)
    labs(
        x = "Opening Gross (in millions)",
        y = "US Total Gross (in millions)"
    ) + theme_minimal()

```


## Inferencia de los coeficientes {.medium}

Cuando trabajamos con distribuciones muestrales, la idea era que:

$$
\bar{X} \xrightarrow{\text{🤞 ojalá 🤞}} \mu
$$

:::{.fragment}

De igual manera, en el modelo de regresión queremos:

$$
\hat{\beta} \xrightarrow{\text{🤞 ojalá 🤞}} \beta
$$
:::



## Inferencia de los coeficientes {.medium}

$$\widehat{\text{US Total Gross}} = 5,108,220 + 3.12 \times \text{Opening Gross}$$

- Es $\beta_1$ diferente de cero?


::: fragment
```{r}
#| echo: true
tidy(hollywood_model, conf.int = TRUE)
```
:::


## Más pruebas de hipótesis {.medium}

$$H_0:\beta_1=0$$
$$H_1: \beta_1 \neq 0$$

:::{.fragment}

$$Z=\dfrac{3.12-0}{0.218}=14.3>Z_{\frac{\alpha}{2}}=1.96$$

- Rechazamos la $H_0$ a un nivel de significancia del 5%! 

- El p-value es 7.07e-23 (en notación científica), el cual es mucho menor a 0.05. 

:::


# Regresión Lineal Múltiple {#multiple}


## Regresión Múltiple {.medium}

No estamos limitados a una sola variable explicativa!

$$
\hat{y} = \hat{\beta_0}  + \hat{\beta_1} x_1 + \hat{\beta_2} x_2 + \cdots + \hat{\beta_n} x_n 
$$

:::{.fragment}

```{r}
#| echo: true
hollywood_model <- lm(us_gross ~ opening_gross + budget + sequel, data=hollywood)
```

$$
\widehat{\text{US Gross}} = \hat{\beta_0} + \hat{\beta_1} \text{Opening Gross} + \hat{\beta_2} \text{Budget} + \hat{\beta_3} \text{Sequel}
$$

:::


## Regresión Múltiple {.medium}

```{r}
#| echo: true
hollywood_model <- lm(us_gross ~ opening_gross + budget + sequel, data=hollywood)
tidy(hollywood_model, conf.int = TRUE)
```


$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 11,929,834 \times \text{Sequel}
\end{aligned}
$$


## Predicción en Regresión Múltiple {.medium}

Así como en el caso con una variable, usamos el comando `predict()` para predecir $\widehat{\text{US Gross}}$. En este caso, necesitamos al menos un valor para cada variable que está en la regresión.

```{r}
#| echo: true
#| eval: true
multiples_valores <- data.frame(opening_gross=50000000,
                             budget=100000000,
                             sequel=1)
predict(hollywood_model, newdata = multiples_valores)

```

## Predicción en Regresión Múltiple {.medium}

Hagamos una predicción para una de las observaciones en nuestros datos. En este caso, para la película "The Holiday".

```{r}
#| echo: true
#| eval: true
# Seleccionemos las 3 variables dependientes para The Holiday
the_holiday <- hollywood %>% 
  filter(movie=="The Holiday") %>%
  select(opening_gross, budget, sequel)

# Usamos el comando predict nuevamente
predicho <- predict(hollywood_model, newdata = the_holiday)
predicho
```


## Predicción en Regresión Múltiple {.medium}


- ¿Es precisa nuestra estimación?

```{r}
#| echo: true
#| eval: true
# El valor observado
observado <- hollywood %>%
  filter(movie == "The Holiday") %>%
  pull(us_gross)
observado
```

- El residuo para "The Holiday" será:

```{r}
#| echo: true
#| eval: true
observado-predicho
```


## Variables Categóricas vs Variables Continuas {.medium}

```{r}
#| eval: true
#| echo: false
#| fig-align: "center"
#| out-width: "100%"
knitr::include_graphics("img/slider-switch-plain-80.jpg")

```


## Variables Categóricas vs Variables Continuas {.medium}

```{r}
#| eval: true
#| echo: false
#| fig-align: "center"
#| out-width: "100%"
knitr::include_graphics("img/slider-switch-annotated-80.jpg")

```


##

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

set.seed(123)

# Create a tibble with the same slope but different intercepts for professors and students, adding noise
cookies_data <- tibble(
  cookies = rep(1:7, 2),  # Galletas consumidas (1 through 7 for both groups)
  group = rep(c("Profesores", "Estudiantes"), each = 7),  # Group variable
  happiness = c(0.5 + 0.15 * (1:7) + rnorm(7, sd = 0.2),  # Happiness for professors with noise
                1.5 + 0.15 * (1:7) + rnorm(7, sd = 0.2))  # Happiness for students with noise
)


ggplot(cookies_data, aes(x = cookies, y = happiness)) +
  geom_point( size = 3) +  # Points still colored by group for clarity
  geom_smooth(method = "lm", se = FALSE, color = "#0074D9") +  # Single regression line for the entire dataset
  labs(x = "Galletas consumidas", y = "Nivel de Felicidad") +
  theme_minimal(base_size = 14) +
  coord_cartesian(xlim = c(0, 8), ylim = c(0, 3)) +
  scale_x_continuous(breaks = 0:8) +
  theme(panel.grid.minor = element_blank())


```

##

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

ggplot(cookies_data, aes(x = cookies, y = happiness)) +
  geom_point(aes(color = group), size = 3) +  # Points still colored by group for clarity
  geom_smooth(method = "lm", se = FALSE, color = "#0074D9") +  # Single regression line for the entire dataset
  labs(x = "Galletas consumidas", y = "Nivel de Felicidad", color = "Grupo") +
  theme_minimal(base_size = 14) +
  coord_cartesian(xlim = c(0, 8), ylim = c(0, 3)) +
  scale_color_manual(values = c("Profesores" = "navy", "Estudiantes" = "darkred")) +
  scale_x_continuous(breaks = 0:8) +
  theme(panel.grid.minor = element_blank())


```

##

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

ggplot(cookies_data, aes(x = cookies, y = happiness, color = group)) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE) +  # Add linear regression lines
  labs(x = "Galletas consumidas", y = "Nivel de Felicidad", color = "Grupo") +
  theme_minimal(base_size = 14) +
  coord_cartesian(xlim = c(0, 8), ylim = c(0, 3)) +
  scale_color_manual(values = c("Profesores" = "navy", "Estudiantes" = "darkred")) +
  scale_x_continuous(breaks = 0:8) +
  theme(panel.grid.minor = element_blank())

```


## Variables Categóricas {.medium}


$$\widehat{Felicidad}=\hat{\beta_0}+\hat{\beta_1}\times Galletas+\hat{\beta_2} \times Estudiante$$

:::{.incremental}

- EL intercepto para las observaciones de los profesores será $\hat{\beta_0}$ porque $Estudiante=0$

- El intercepto para las observaciones de los estudiantes será $\hat{\beta_0}+\hat{\beta_2}$ porque $Estudiante=1$
:::


## Filtrar la variación {.medium}

- Cada **X** en el modelo explica una porción de la variación en **Y**

- La interpretación acá es más complicada que en el modelo de regresión simple porque sólo se puede mover una variable a la vez


## Interpretación para variables continuas {.medium}

Manteniendo todo lo demás constante, un incremento de una unidad en **X** está asociado con un incremento/reducción promedio de $\beta_n$ en **Y**

$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 11,929,834 \times \text{Sequel}
\end{aligned}
$$

:::{.fragment}
Manteniendo todo lo demás constante, un incremento de un dólar en el recaudo del primer fin de semana está asociado con un incremento promedio de 2.99 dólares en el recaudo total en US
:::


## Interpretación para variables categóricas {.medium}

Manteniendo todo lo demás constante, **Y** es, en promedio, $\beta_n$ unidades mayor/menor para **X**<sub>n</sub> comparado con **X**<sub>omitida</sub>

$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 11,929,834 \times \text{Sequel}
\end{aligned}
$$


:::{.fragment}

Manteniendo todo lo demás constante, las sequelas están asociadas a un recaudo promedio menor, en aproximadamente $11.9 millones, comparadas con las películas que no son secuelas

:::


## Variable categóricas con más de 2 niveles {.medium}

$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 11,929,834 \times \text{Sequel} - 15,000,000 \times \text{Trilogy}
\end{aligned}
$$

Si es la primera película $Sequel=Trilogy=0$, el modelo es:

$$\widehat{\text{US Gross}} = -8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget}$$


## Variable categóricas con más de 2 niveles {.medium}

$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 11,929,834 \times \text{Sequel} - 15,000,000 \times \text{Trilogy}
\end{aligned}
$$


Si es trilogía, entonces $Sequel=0$ y $Trilogy=1$. En este caso, el modelo es:

$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 15,000,000 
\end{aligned}
$$

Manteniendo lo demás constante, estimamos que una trilogía tendrá, en promedio, un recaudo 15 millones de dólares menor que una primera entrega


## ¿Qué tan bueno es el modelo? {.medium}

### R-Squared

El $R^2$ es el porcentaje de la varianza de la variable dependiente explicada por el modelo de regresión

$$R^2=Corr(x,y)^2=Corr(y,\hat{y})$$

- Está entre 0 (nuestro modelo no predice nada) y 1 (predicción perfecta)

- No tiene unidad de medida



## ¿Qué tan bueno es el modelo? {.medium}

Con la función `glance()` podemos ver diferentes aspectos que evalúan el modelo:

```{r}
#| echo: true
glance(hollywood_model)
```

:::{.fragment}
Este modelo de regresión explica el 79% de la varianza del recaudo total en US

```{r}
#| echo: true
hollywood_model <- lm(us_gross ~ opening_gross + budget + sequel, data=hollywood)
```
:::



