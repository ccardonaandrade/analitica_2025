---
title: Anal铆tica de los Negocios
author: Carlos Cardona Andrade
subtitle: Intro a la Regresi贸n Lineal
execute:
  freeze: auto
  echo: true
  fig-width: 6
  fig-height: 5
format:
  revealjs: 
   theme: ../slides.scss
   header-includes: |
      <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" rel="stylesheet"/>
   slide-number: true
   show-slide-number: all
   transition: fade
   progress: true
   multiplex: false
   scrollable: false
   preview-links: false
   hide-inactive-cursor: true
   highlight-style: printing
   pause: true
---


## Plan para hoy

1. [Correlaci贸n](#corr)

2. [Regresi贸n Lineal Simple](#lm)

3. [Regresi贸n Lineal M煤ltiple](#multiple)

# Correlaci贸n {#corr}


## US Total Gross vs Opening Gross {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

library(tidyverse)
library(readxl)
library(janitor)
hollywood <- read_excel("C:/Users/ccard/Downloads/KEL702-XLS-ENG.xls", sheet = "Exhibit 1")
hollywood <- hollywood %>%
  clean_names()
hollywood <- hollywood %>% rename(us_gross = total_u_s_gross)
hollywood <- hollywood %>% rename(non_us_gross = total_non_u_s_gross)

```

```{r}
#| echo: true
#| eval: true
#| fig-align: center
#| code-fold: true

ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
    geom_point() +
    labs(
        x = "Opening Gross (in millions)",
        y = "US Total Gross (in millions)"
    ) +
    theme_minimal()

```

## La correlaci贸n en R {.medium}

- Podemos utilizar un diagrama de dispersi贸n para realizar un primer an谩lisis de la relaci贸n entre dos variables

- El coeficiente de correlaci贸n (lineal) es utilizado para medir la fuerza de la asociaci贸n (lineal) entre dos variables

- La correlaci贸n entre el recaudo en US y el recaudo el primer fin de semana:

```{r}
#| echo: true
cor(hollywood$us_gross,hollywood$opening_gross)
```


## Funci贸n `corrplot` {.medium}

```{r}
#| echo: true
#| eval: false
#| fig-align: center

# RECUERDEN INSTALAR EL PAQUETE PRIMERO!!!
# install.packages("corrplot")

# Cargamos el paquete
library(corrplot)

# Creemos una base de datos temporal s贸lo con estas 4 variables
hollywood_sub <- hollywood %>% select( us_gross, opening_gross, non_us_gross, budget) 

# Creemos la matriz de correlaciones
corrplot(cor(hollywood_sub ),
         method = "number",
         type = "upper")

```



## Funci贸n `corrplot` {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: center

# RECUERDEN INSTALARLA PRIMERO!!!
# install.packages("corrplot)

# Cargamos el paquete
library(corrplot)

# Creemos una base de datos temporal s贸lo con estas 4 variables
hollywood_sub <- hollywood %>% select( us_gross, opening_gross, non_us_gross, budget) 

# Creemos la matriz de correlaciones
corrplot(cor(hollywood_sub ),
         method = "number",
         type = "upper")

```



## La correlaci贸n no es suficiente {.medium}


```{r}
#| echo: false
#| eval: true
#| fig-align: center

library(datasauRus)
library(patchwork)

dino <- datasaurus_dozen %>%
  filter(dataset == "dino")

star <- datasaurus_dozen %>%
  filter(dataset == "star")

hlines <- datasaurus_dozen %>%
  filter(dataset == "h_lines")

dino %>%
  summarize(
      mean_x    = mean(x),
      mean_y    = mean(y),
      std_dev_x = sd(x),
      std_dev_y = sd(y),
      corr_x_y  = cor(x, y)
  )



```



```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 7
#| fig-height: 3.5

ggplot(dino, aes(x=x, y=y))+
  geom_point(color = "darkred") + theme_minimal()
```




## La correlaci贸n no es suficiente {.medium}


```{r}
#| echo: false
#| eval: true
#| fig-align: center
star %>%
  summarize(
      mean_x    = mean(x),
      mean_y    = mean(y),
      std_dev_x = sd(x),
      std_dev_y = sd(y),
      corr_x_y  = cor(x, y)
  )
```

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 7
#| fig-height: 3.5
ggplot(star, aes(x=x, y=y))+
  geom_point(color = "navy") + theme_minimal()

```


## La correlaci贸n no es suficiente {.medium}


```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 7
#| fig-height: 3.5
hlines %>%
  summarize(
      mean_x    = mean(x),
      mean_y    = mean(y),
      std_dev_x = sd(x),
      std_dev_y = sd(y),
      corr_x_y  = cor(x, y)
  )
```

```{r}
#| echo: false
#| eval: true
#| fig-align: center

ggplot(hlines, aes(x=x, y=y))+
  geom_point(color = "orange") + theme_minimal()

```



# Regresi贸n Lineal Simple {#lm}

     
## Partes esenciales de una regresi贸n {.medium}

::: columns
::: {.column width="50%"}
### Y  {.text-orange-gold .center}

- Variable dependiente

- Variable resultado

- B谩sicamente lo que queremos predecir o explicar

:::

::: {.column .fragment width="50%"}

### X  {.text-orange-gold .center}

- Variable explicativa

- Predictor

- Variable independiente

- Lo que usamos para predecir o explicar Y
:::
:::


## 驴Por qu茅 una regresi贸n? {.medium}

Usualmente ajustamos a una l铆nea por dos razones:

### Predicci贸n

- Predecir el futuro

- Nos enfocamos en Y

- Netflix tratando de predecir la siguiente serie que veremos

### Explicaci贸n

- Explicar el efecto de X en Y

- Nos enfocamos en X

- Netflix evaluando el efecto de la hora del d铆a en la selecci贸n de una serie


## 驴C贸mo? {.medium}

1. Graficar X y Y

2. Dibujar una recta que se aproxime a la relaci贸n observada (ojal谩 funcione para datos que no est谩n en la muestra)

3. Estimar los n煤meros que componen esa recta

4. Interpretar esos n煤meros

```{r}
#| echo: false
library(tidyverse)
library(patchwork)
library(broom)
library(knitr)
galletas <- tibble(felicidad = c(0.5, 2, 1, 2.5, 3, 1.5, 2, 2.5, 2, 3),
                  galletas = 1:10)

galletas_datos <- galletas
modelo_galletas <- lm(felicidad ~ galletas, data = galletas_datos)
predict_galletas <- augment(modelo_galletas)
```



## Galletas y Felicidad {.medium}

::: {.tbl-classic .tbl-larger .center-text}


```{r}
#| echo: false
#| eval: true

galletas |> 
  knitr::kable(format = "html") |> 
  kableExtra::kable_styling(font_size = 30) # Adjust the font size as needed
```

:::

## 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4



base_cookies <- ggplot(predict_galletas, aes(x = galletas, y = felicidad)) +
  geom_point(size = 3) +
  coord_cartesian(xlim = c(0, 10), ylim = c(0, 3)) +
  scale_x_continuous(breaks = 0:10) +
  labs(x = "Galletas consumidas", y = "Nivel de Felicidad") +
  theme_minimal(base_size = 14) +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold"))

base_cookies
```




## 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

base_cookies +
  geom_smooth(method = lm, color = "#0074D9", formula = y ~ splines::bs(x, 7), se = FALSE)
```

## 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

base_cookies +
  geom_smooth(method = "loess", color = "#0074D9", se = FALSE)
```

##

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

base_cookies +
  geom_smooth(method = "lm", color = "#0074D9", se = FALSE)
```

##

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

galletas_con_residuo <- base_cookies +
  geom_smooth(method = "lm", color = "#0074D9", se = FALSE) +
  geom_segment(aes(xend = galletas, yend = .fitted), color = "#FF851B", size = 1)

galletas_con_residuo
```

## 

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

galletas_solo_residuo <- ggplot(predict_galletas, aes(x = galletas, y = .resid)) +
  geom_hline(yintercept = 0, color = "#B10DC9", size = 1) +
  geom_point(size = 3) +
  geom_segment(aes(xend = galletas, yend = 0), color = "#FF851B", size = 1) +
  coord_cartesian(xlim = c(0, 10), ylim = c(-1.5, 1.5)) +
  scale_x_continuous(breaks = 0:10) +
  labs(x = "Galletas consumidas", y = "Distancia a la l铆nea") +
  theme_minimal(base_size = 14) +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold"))

galletas_solo_residuo
```

##


```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

(galletas_con_residuo + labs(title = "Galletas y Felicidad")) + 
  (galletas_solo_residuo + labs(title = "Residuos"))
```

## Pendiente de una recta {.medium}

$$
y = mx + b
$$

::: {.tbl-classic .tbl-larger .center-text}


|     |                                          |
|:---:|:----------------------------------------:|
| $y$ |                Un n煤mero                 |
| $x$ |                Un n煤mero                 |
| $m$ | La pendiente $\frac{\Delta y}{\Delta x}$ |
| $b$ |          El intercepto con $y$           |

:::

## Pendiente de una recta {.medium}

::: columns
::: {.column width="50%"}
$$
y = 2x - 1
$$

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 4.8
#| fig-height: 3.5

ggplot(data = tibble(x = 0:5), aes(x = x)) +
  stat_function(fun = function(x) 2 * x - 1, 
                color = "#BF3984", size = 1.5) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = 0:5) +
  scale_y_continuous(breaks = -1:9) +
  theme(panel.grid.minor = element_blank())
```

:::



::: {.column .fragment width="50%"}
$$
y = -0.5x + 6
$$

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 4.8
#| fig-height: 3.5

ggplot(data = tibble(x = 0:14), aes(x = x)) +
  stat_function(fun = function(x) -0.5 * x + 6, 
                color = "#BF3984", size = 1.5) +
  geom_vline(xintercept = 0) +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = 0:14) +
  scale_y_continuous(breaks = -1:9) +
  theme(panel.grid.minor = element_blank())
```

:::
:::

## Regresi贸n lineal simple {.medium}

$$
Y = \beta_0 + \beta_1 X + \varepsilon
$$

-   $\beta_1$: la pendiente verdadera de la relaci贸n entre $X$ y $Y$

-   $\beta_0$: el intercepto verdadero de la relaci贸n entre $X$ y $Y$

-   $\varepsilon$: el error

## Regresi贸n lineal simple {.medium}

$$
\hat{Y} = \hat{\beta_0} + \hat{\beta_1} X 
$$

-   $\hat{\beta_1}$: la pendiente estimado de la relaci贸n entre $X$ y $Y$

-   $\hat{\beta_0}$: el intercepto estimado de la relaci贸n entre $X$ y $Y$

-   No hay error!!!

## Modelo de Regresi贸n {.medium}

::: columns
::: {.column width="40%"}
$$  
  \begin{aligned}
Y &= \color{#0074D9}{\text{Modelo}} + \color{#FF851B}{\text{Error}} \\
  &= \color{#0074D9}{f(X)} + \color{#FF851B}{\varepsilon}
\end{aligned}
$$
:::

::: {.column width="60%"}
```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| out-width: "100%"


galletas_con_residuo
```
:::
:::

## Residuos {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| out-width: "100%"


galletas_con_residuo

```

$$
\text{Residuo} = \text{Observado} - \text{Predicho} = y - \hat{y}
$$

## La l铆nea de los m铆nimos cuadrados {.medium}

-   El residuo para la observaci贸n $i^{th}$ es:

$$e_i= \text{Observado} - \text{Predicho}=y_i - \hat{y_i}$$ - La **suma de los residuos al cuadrado** es:

$$e_1^2+e_2^2+e_3^2+..+e_n^2$$

-   La **l铆nea de los m铆nimos cuadrados** es la que minimiza la suma de los residuos al cuadrado

## 

```{r}
#| eval: true
#| echo: false
#| fig-align: "center"
#| out-width: "100%"
knitr::include_graphics("img/meme.png")

```

## Construyendo modelos en R {.medium}

-   La sint谩xis para los resultados del modelo es:

```{r}
#| eval: false
#| echo: true

name_of_model <- lm(Y ~ X, data = DATA)

summary(name_of_model)  # Para ver los detalles del modelo
```

::: fragment
-   Otras opciones para evaluar el modelo son:

```{r}
#| eval: false
#| echo: true

library(broom)

# Convierte los resultados del modelo a un data frame para graficar
tidy(name_of_model)

# Convierte los par谩metros que eval煤an el modelo a un data frame
glance(name_of_model)
```
:::

## Modelando Galletas y Felicidad {.medium}

::: columns
::: {.column width="40%"}
$$\widehat{Felicidad}=\hat{\beta_0}+\hat{\beta_1}\times Galletas$$

```{r}
#| echo: true
#| eval: true
modelo_felicidad <- 
  lm(felicidad ~ galletas,
     data = galletas_datos)
```
:::

::: {.column width="60%"}
```{r}
#| echo: false
#| label: cookies-happiness-again
#| results: hide


base_cookies +
  geom_smooth(method = "lm", color = "#0074D9") +
  coord_cartesian(xlim = c(0, 10), ylim = c(0, 4))
```
:::
:::

## Modelando Galletas y Felicidad {.medium}

Podemos ver los coeficientes, error est谩ndar, p-value e IC:

```{r}
#| echo: true
tidy(modelo_felicidad, conf.int = TRUE)
```

::: fragment
Para ver aspectos evaluando el ajuste del modelo:
```{r}
#| echo: true
glance(modelo_felicidad)
```
:::

## Traduciendo los resultados a matem谩ticas {.medium}

::: columns
::: {.column width="40%"}
```{r}
#| echo: false
tidy(modelo_felicidad, conf.int = TRUE) |> 
  select(term, estimate)
```

$$
\begin{aligned}
&\widehat{Felicidad} = \\ 
&\hat{\beta_0}+\hat{\beta_1}\times Galletas
\end{aligned}
$$

$$
\begin{aligned}
&\widehat{Felicidad} = \\ 
&1.1 + 0.16 \times Galletas
\end{aligned}
$$
:::

::: {.column width="60%"}
```{r}
#| echo: false
base_cookies +
  geom_smooth(method = "lm", color = "#0074D9") +
  coord_cartesian(xlim = c(0, 10), ylim = c(0, 4))
```
:::
:::

## Interpretaci贸n de los coeficientes {.medium}

Un incremento en una unidad de $X$ est谩 *asociado* con un incremento (o reducci贸n) promedio de $\beta_1$ unidades en $Y$

$$\widehat{Felicidad}=\hat{\beta_0}+\hat{\beta_1}\times Galletas$$

$$\widehat{Felicidad} = 1.1 + 0.16 \times Galletas$$

:::{.incremental}

- En *promedio*, una galleta adicional est谩 asociado a aumento en la felicidad de 0.16 unidades

- Si no hay consumo de galletas, esperamos que el puntaje de felicidad sea 1.1 unidades
:::


## 驴Es el intercepto importante? {.medium}

- La interpretaci贸n del intercepto es importante si en el contexto de los datos:

  1. La variable independiente puede tomar valores iguales o cercanos a cero
  
  2. La variable independiente tiene valores cercanos a cero en los datos observados
  
:::{.incremental}
  
- En caso contrario, el intercepto no tiene ninguna interpretaci贸n pr谩ctica

- Veremos m谩s ejemplos sobre esto m谩s adelante...
:::


## Volvamos a Hollywood Rules  {.medium}

- Seg煤n la sabidur铆a popular en Hollywood, el recaudo durante el primer fin de semana es un fuerte predictor del 茅xito comercial de una pel铆cula
- Grafiquemos la relaci贸n entre el recaudo en Estados Unidos y el recaudo en el primer fin de semana para evaluar esta creencia:




## Volvamos a Hollywood Rules  {.medium}


```{r}
#| echo: false
#| eval: true
#| fig-align: center

ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
    geom_point() +
    labs(
        x = "Opening Gross (in millions)",
        y = "US Total Gross (in millions)"
    ) +
    theme_minimal()

```



## Volvamos a Hollywood Rules  {.medium}

```{r}
#| echo: true
#| eval: true
hollywood_model <- lm(us_gross ~ opening_gross, data=hollywood)
tidy(hollywood_model, conf.int = TRUE)

```

:::{.fragment}

Entonces nuestro modelo lineal es:

$$\widehat{\text{US Total Gross}} = 5,108,220 + 3.12 \times \text{Opening Gross}$$

:::

:::{.fragment}
驴Cu谩l es la interpretaci贸n de $\hat{\beta_1}$ en este caso?驴Y de $\hat{\beta_0}$?
:::



## 驴 C贸mo graficar la l铆nea de regresi贸n? {.medium}

`geom_smooth(method="lm")`es la funci贸n dentro de ggplot para gr谩ficar la l铆nea de regresi贸n y su respectivo intervalo de confianza.


```{r}
#| echo: true
#| eval: false
#| fig-width: 8
#| fig-height: 4
#| fig-align: center
#| code-line-numbers: "3"
ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
    geom_point() +
    geom_smooth(method="lm") +
    labs(
        x = "Opening Gross (in millions)",
        y = "US Total Gross (in millions)"
    ) +
    theme_minimal()

```


## 驴 C贸mo graficar la l铆nea de regresi贸n? {.medium}


```{r}
#| echo: false
#| eval: true
#| fig-width: 8
#| fig-height: 4
#| fig-align: center

ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
    geom_point() +
    geom_smooth(method="lm") +
    labs(
        x = "Opening Gross (in millions)",
        y = "US Total Gross (in millions)"
    ) +
    theme_minimal()

```


## Predicci贸n  {.medium}

Seg煤n nuestro modelo, 驴cu谩l ser铆a el recaudo en US de una pel铆cula cuyo recaudo en el primer fin de semana fue de \$50,000,000?



$$  
  \begin{aligned}
\widehat{\text{US Gross}} &= 5,108,220 + 3.12 \times \text{Opening Gross} \\
  &= 5,108,220 + 3.12 \times \color{red}{50,000,000} \\
  &= 161,108,220
\end{aligned}
$$

## Predicci贸n con R {.medium}

El comando `predict()` nos permite predecir $\widehat{\text{US Gross}}$ para uno o varios valores:



```{r}
#| echo: true
#| eval: true

# Creamos los valores para los cuales queremos predecir
valores_opening <- data.frame(opening_gross = c(20000000,40000000,50000000))


# Predice los valores con los coeficientes estimados
# en hollywood_model
predict(hollywood_model, newdata = valores_opening)

```


## Predicci贸n  {.medium}


```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 8

model <- lm(us_gross ~ opening_gross , data = hollywood)

# Predict the corresponding y value when x = 50
predicted_y <- predict(model, newdata = data.frame(opening_gross = 50 * 1000000))

# Plot
ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
  geom_point() +
  geom_smooth(method = "lm") +
  geom_vline(xintercept = 50, linetype = "dashed", color = "blue") +   # Dashed vertical line at x = 50
  geom_hline(yintercept = predicted_y/ 1000000, linetype = "dashed", color = "blue") + # Dashed horizontal line at predicted y
  geom_point(aes(x = 50, y = predicted_y/ 1000000), color = "red", size = 3) + # Point at (50, predicted_y)
  labs(
    x = "Opening Gross (in millions)",
    y = "US Total Gross (in millions)"
  ) +
  theme_minimal()
```





## 驴Es posible la extrapolaci贸n? {.medium}

Extrapolar es tratar de predecir Y fuera del rango de valores de X. Es posible pero no aconsejable.

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-height: 4
#| fig-width: 8
# Predict the corresponding y value when x = 80
predicted_y <- predict(model, newdata = data.frame(opening_gross = 80 * 1000000))

# Plot
ggplot(data = hollywood, aes(x = (opening_gross / 1000000), y = (us_gross / 1000000))) +
    geom_point() +
    geom_smooth(method = "lm") +
    geom_vline(xintercept = 80, linetype = "dashed", color = "blue") +   # Dashed vertical line at x = 80
    geom_hline(yintercept = predicted_y/ 1000000, linetype = "dashed", color = "blue") + # Dashed horizontal line at predicted y
    geom_point(aes(x = 80, y = predicted_y/ 1000000), color = "red", size = 3) + # Point at (80, predicted_y)
    labs(
        x = "Opening Gross (in millions)",
        y = "US Total Gross (in millions)"
    ) + theme_minimal()

```


## Inferencia de los coeficientes {.medium}

Cuando trabajamos con distribuciones muestrales, la idea era que:

$$
\bar{X} \xrightarrow{\text{ ojal谩 }} \mu
$$

:::{.fragment}

De igual manera, en el modelo de regresi贸n queremos:

$$
\hat{\beta} \xrightarrow{\text{ ojal谩 }} \beta
$$
:::



## Inferencia de los coeficientes {.medium}

$$\widehat{\text{US Total Gross}} = 5,108,220 + 3.12 \times \text{Opening Gross}$$

- Es $\beta_1$ diferente de cero?


::: fragment
```{r}
#| echo: true
tidy(hollywood_model, conf.int = TRUE)
```
:::


## M谩s pruebas de hip贸tesis {.medium}

$$H_0:\beta_1=0$$
$$H_1: \beta_1 \neq 0$$

:::{.fragment}

$$Z=\dfrac{3.12-0}{0.218}=14.3>Z_{\frac{\alpha}{2}}=1.96$$

- Rechazamos la $H_0$ a un nivel de significancia del 5%! 

- El p-value es 7.07e-23 (en notaci贸n cient铆fica), el cual es mucho menor a 0.05. 

:::


# Regresi贸n Lineal M煤ltiple {#multiple}


## Regresi贸n M煤ltiple {.medium}

No estamos limitados a una sola variable explicativa!

$$
\hat{y} = \hat{\beta_0}  + \hat{\beta_1} x_1 + \hat{\beta_2} x_2 + \cdots + \hat{\beta_n} x_n 
$$

:::{.fragment}

```{r}
#| echo: true
hollywood_model <- lm(us_gross ~ opening_gross + budget + sequel, data=hollywood)
```

$$
\widehat{\text{US Gross}} = \hat{\beta_0} + \hat{\beta_1} \text{Opening Gross} + \hat{\beta_2} \text{Budget} + \hat{\beta_3} \text{Sequel}
$$

:::


## Regresi贸n M煤ltiple {.medium}

```{r}
#| echo: true
hollywood_model <- lm(us_gross ~ opening_gross + budget + sequel, data=hollywood)
tidy(hollywood_model, conf.int = TRUE)
```


$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 11,929,834 \times \text{Sequel}
\end{aligned}
$$


## Predicci贸n en Regresi贸n M煤ltiple {.medium}

As铆 como en el caso con una variable, usamos el comando `predict()` para predecir $\widehat{\text{US Gross}}$. En este caso, necesitamos al menos un valor para cada variable que est谩 en la regresi贸n.

```{r}
#| echo: true
#| eval: true
multiples_valores <- data.frame(opening_gross=50000000,
                             budget=100000000,
                             sequel=1)
predict(hollywood_model, newdata = multiples_valores)

```

## Predicci贸n en Regresi贸n M煤ltiple {.medium}

Hagamos una predicci贸n para una de las observaciones en nuestros datos. En este caso, para la pel铆cula "The Holiday".

```{r}
#| echo: true
#| eval: true
# Seleccionemos las 3 variables dependientes para The Holiday
the_holiday <- hollywood %>% 
  filter(movie=="The Holiday") %>%
  select(opening_gross, budget, sequel)

# Usamos el comando predict nuevamente
predicho <- predict(hollywood_model, newdata = the_holiday)
predicho
```


## Predicci贸n en Regresi贸n M煤ltiple {.medium}


- 驴Es precisa nuestra estimaci贸n?

```{r}
#| echo: true
#| eval: true
# El valor observado
observado <- hollywood %>%
  filter(movie == "The Holiday") %>%
  pull(us_gross)
observado
```

- El residuo para "The Holiday" ser谩:

```{r}
#| echo: true
#| eval: true
observado-predicho
```


## Variables Categ贸ricas vs Variables Continuas {.medium}

```{r}
#| eval: true
#| echo: false
#| fig-align: "center"
#| out-width: "100%"
knitr::include_graphics("img/slider-switch-plain-80.jpg")

```


## Variables Categ贸ricas vs Variables Continuas {.medium}

```{r}
#| eval: true
#| echo: false
#| fig-align: "center"
#| out-width: "100%"
knitr::include_graphics("img/slider-switch-annotated-80.jpg")

```


##

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

set.seed(123)

# Create a tibble with the same slope but different intercepts for professors and students, adding noise
cookies_data <- tibble(
  cookies = rep(1:7, 2),  # Galletas consumidas (1 through 7 for both groups)
  group = rep(c("Profesores", "Estudiantes"), each = 7),  # Group variable
  happiness = c(0.5 + 0.15 * (1:7) + rnorm(7, sd = 0.2),  # Happiness for professors with noise
                1.5 + 0.15 * (1:7) + rnorm(7, sd = 0.2))  # Happiness for students with noise
)


ggplot(cookies_data, aes(x = cookies, y = happiness)) +
  geom_point( size = 3) +  # Points still colored by group for clarity
  geom_smooth(method = "lm", se = FALSE, color = "#0074D9") +  # Single regression line for the entire dataset
  labs(x = "Galletas consumidas", y = "Nivel de Felicidad") +
  theme_minimal(base_size = 14) +
  coord_cartesian(xlim = c(0, 8), ylim = c(0, 3)) +
  scale_x_continuous(breaks = 0:8) +
  theme(panel.grid.minor = element_blank())


```

##

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

ggplot(cookies_data, aes(x = cookies, y = happiness)) +
  geom_point(aes(color = group), size = 3) +  # Points still colored by group for clarity
  geom_smooth(method = "lm", se = FALSE, color = "#0074D9") +  # Single regression line for the entire dataset
  labs(x = "Galletas consumidas", y = "Nivel de Felicidad", color = "Grupo") +
  theme_minimal(base_size = 14) +
  coord_cartesian(xlim = c(0, 8), ylim = c(0, 3)) +
  scale_color_manual(values = c("Profesores" = "navy", "Estudiantes" = "darkred")) +
  scale_x_continuous(breaks = 0:8) +
  theme(panel.grid.minor = element_blank())


```

##

```{r}
#| echo: false
#| eval: true
#| fig-align: "center"
#| fig-width: 8
#| fig-height: 4

ggplot(cookies_data, aes(x = cookies, y = happiness, color = group)) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE) +  # Add linear regression lines
  labs(x = "Galletas consumidas", y = "Nivel de Felicidad", color = "Grupo") +
  theme_minimal(base_size = 14) +
  coord_cartesian(xlim = c(0, 8), ylim = c(0, 3)) +
  scale_color_manual(values = c("Profesores" = "navy", "Estudiantes" = "darkred")) +
  scale_x_continuous(breaks = 0:8) +
  theme(panel.grid.minor = element_blank())

```


## Variables Categ贸ricas {.medium}


$$\widehat{Felicidad}=\hat{\beta_0}+\hat{\beta_1}\times Galletas+\hat{\beta_2} \times Estudiante$$

:::{.incremental}

- EL intercepto para las observaciones de los profesores ser谩 $\hat{\beta_0}$ porque $Estudiante=0$

- El intercepto para las observaciones de los estudiantes ser谩 $\hat{\beta_0}+\hat{\beta_2}$ porque $Estudiante=1$
:::


## Filtrar la variaci贸n {.medium}

- Cada **X** en el modelo explica una porci贸n de la variaci贸n en **Y**

- La interpretaci贸n ac谩 es m谩s complicada que en el modelo de regresi贸n simple porque s贸lo se puede mover una variable a la vez


## Interpretaci贸n para variables continuas {.medium}

Manteniendo todo lo dem谩s constante, un incremento de una unidad en **X** est谩 asociado con un incremento/reducci贸n promedio de $\beta_n$ en **Y**

$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 11,929,834 \times \text{Sequel}
\end{aligned}
$$

:::{.fragment}
Manteniendo todo lo dem谩s constante, un incremento de un d贸lar en el recaudo del primer fin de semana est谩 asociado con un incremento promedio de 2.99 d贸lares en el recaudo total en US
:::


## Interpretaci贸n para variables categ贸ricas {.medium}

Manteniendo todo lo dem谩s constante, **Y** es, en promedio, $\beta_n$ unidades mayor/menor para **X**<sub>n</sub> comparado con **X**<sub>omitida</sub>

$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 11,929,834 \times \text{Sequel}
\end{aligned}
$$


:::{.fragment}

Manteniendo todo lo dem谩s constante, las sequelas est谩n asociadas a un recaudo promedio menor, en aproximadamente $11.9 millones, comparadas con las pel铆culas que no son secuelas

:::


## Variable categ贸ricas con m谩s de 2 niveles {.medium}

$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 11,929,834 \times \text{Sequel} - 15,000,000 \times \text{Trilogy}
\end{aligned}
$$

Si es la primera pel铆cula $Sequel=Trilogy=0$, el modelo es:

$$\widehat{\text{US Gross}} = -8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget}$$


## Variable categ贸ricas con m谩s de 2 niveles {.medium}

$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 11,929,834 \times \text{Sequel} - 15,000,000 \times \text{Trilogy}
\end{aligned}
$$


Si es trilog铆a, entonces $Sequel=0$ y $Trilogy=1$. En este caso, el modelo es:

$$  
  \begin{aligned}
\widehat{\text{US Gross}} = &-8,785,254 + 2.99 \times \text{Opening Gross} + 0.356 \times \text{Budget} \\
  & - 15,000,000 
\end{aligned}
$$

Manteniendo lo dem谩s constante, estimamos que una trilog铆a tendr谩, en promedio, un recaudo 15 millones de d贸lares menor que una primera entrega


## 驴Qu茅 tan bueno es el modelo? {.medium}

### R-Squared

El $R^2$ es el porcentaje de la varianza de la variable dependiente explicada por el modelo de regresi贸n

$$R^2=Corr(x,y)^2=Corr(y,\hat{y})$$

- Est谩 entre 0 (nuestro modelo no predice nada) y 1 (predicci贸n perfecta)

- No tiene unidad de medida



## 驴Qu茅 tan bueno es el modelo? {.medium}

Con la funci贸n `glance()` podemos ver diferentes aspectos que eval煤an el modelo:

```{r}
#| echo: true
glance(hollywood_model)
```

:::{.fragment}
Este modelo de regresi贸n explica el 79% de la varianza del recaudo total en US

```{r}
#| echo: true
hollywood_model <- lm(us_gross ~ opening_gross + budget + sequel, data=hollywood)
```
:::



