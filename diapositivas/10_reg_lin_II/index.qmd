---
title: Anal√≠tica de los Negocios
author: Carlos Cardona Andrade
subtitle: M√°s en Regresi√≥n Lineal 
execute:
  freeze: auto
  echo: true
  fig-width: 6
  fig-height: 5
format:
  revealjs: 
   theme: ../slides.scss
   header-includes: |
      <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" rel="stylesheet"/>
   slide-number: true
   show-slide-number: all
   transition: fade
   progress: true
   multiplex: false
   scrollable: false
   preview-links: false
   hide-inactive-cursor: true
   highlight-style: printing
   pause: true
---



```{r}
#| eval: true
#| echo: false
library(pacman)
p_load(broom, latex2exp, ggplot2, ggthemes, viridis, dplyr, magrittr, knitr, parallel,gtools, readxl)

# Define pink color
red_pink <- "#e64173"

theme_empty <- theme_bw() + theme(
  line = element_blank(),
  rect = element_blank(),
  strip.text = element_blank(),
  axis.text = element_blank(),
  plot.title = element_blank(),
  axis.title = element_blank(),
  plot.margin = structure(c(0, 0, 0, 0), unit = "lines", valid.unit = 3L, class = "unit"),
  legend.position = "none"
)


# Set population and sample sizes
n_p <- 100
n_s <- 30
# Set the seed
set.seed(12468)
# Generate data
pop_df <- tibble(
  i = 3,
  x = rnorm(n_p, mean = 5, sd = 1.5),
  e = rnorm(n_p, mean = 0, sd = 1),
  y = i + 0.5 * x + e,
  row = rep(1:sqrt(n_p), times = sqrt(n_p)),
  col = rep(1:sqrt(n_p), each = sqrt(n_p)),
  s1 = sample(x = c(rep(T, n_s), rep(F, n_p - n_s))),
  s2 = sample(x = c(rep(T, n_s), rep(F, n_p - n_s))),
  s3 = sample(x = c(rep(T, n_s), rep(F, n_p - n_s)))
)
# Regressions
lm0 <- lm(y ~ x, data = pop_df)
lm1 <- lm(y ~ x, data = filter(pop_df, s1 == T))
lm2 <- lm(y ~ x, data = filter(pop_df, s2 == T))
lm3 <- lm(y ~ x, data = filter(pop_df, s3 == T))


# Simulation

```



## Plan para hoy

1. [Poblaci√≥n, Muestra y Regresi√≥n](#pobreg)

2. [Condiciones del modelo](#condic)

3. [Consideraciones para una Regresi√≥n](#regresion)

4. [Transformaci√≥n Logar√≠tmica](#log)


# Poblaci√≥n, Muestra y Regresi√≥n {#pobreg}

## Regresi√≥n Poblacional - Ejemplo {.medium}

- 100 estudiantes est√°n tomando Anal√≠tica de los Negocios y queremos saber el efecto de comer galletas en la felicidad para todos ellos. Asumamos que tenemos los datos para todos los estudiantes.

- Luego tomemos muestras de 30 estudiantes y miremos c√≥mo los coeficientes de la siguiente regresi√≥n var√≠an de acuerdo a la muestra:

$$ felicidad_i = \beta_0 + \beta_1 galletas_i + e_i $$

## Regresi√≥n Poblacional {.medium}


$$ felicidad_i = `r round(lm0$coefficients[1], 2)` + `r round(lm0$coefficients[2], 2)` galletas_i + e_i $$

::::: {.columns}

:::: {.column width="50%"}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
ggplot(data = pop_df, aes(x = row, y = col)) +
geom_point(color = "darkslategray", size = 10) +
theme_empty
```

::::

:::: {.column .fragment width="50%"}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
ggplot(data = pop_df, aes(x = x, y = y)) +
geom_abline(
  intercept = lm0$coefficients[1], slope = lm0$coefficients[2],
  color = red_pink, size = 3
) +
geom_point(color = "darkslategray", size = 6) +
theme_empty
```


::::

:::::



## Regresi√≥n para la Muestra 1 {.medium}


$$ felicidad_i = `r round(lm0$coefficients[1], 2)` + `r round(lm0$coefficients[2], 2)` galletas_i + e_i $$

::::: {.columns}

:::: {.column width="50%"}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
ggplot(data = pop_df, aes(x = row, y = col, shape = s1)) +
geom_point(color = "darkslategray", size = 10) +
scale_shape_manual(values = c(1, 19)) +
theme_empty
```

::::

:::: {.column .fragment width="50%"}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
ggplot(data = pop_df, aes(x = x, y = y)) +
geom_abline(
  intercept = lm0$coefficients[1], slope = lm0$coefficients[2],
  color = red_pink, size = 3, alpha = 0.3
) +
geom_point(aes(shape = s1), color = "darkslategray", size = 6) +
geom_abline(
  intercept = lm1$coefficients[1], slope = lm1$coefficients[2],
  size = 2, linetype = 2, color = "black"
) +
scale_shape_manual(values = c(1, 19)) +
theme_empty
```

$\widehat{felicidad}_i = `r round(lm1$coefficients[1], 2)` + `r round(lm1$coefficients[2], 2)` galletas_i$


::::

:::::



## Regresi√≥n para la Muestra 2 {.medium}


$$ felicidad_i = `r round(lm0$coefficients[1], 2)` + `r round(lm0$coefficients[2], 2)` galletas_i + e_i $$

::::: {.columns}

:::: {.column width="50%"}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
ggplot(data = pop_df, aes(x = row, y = col, shape = s2)) +
geom_point(color = "darkslategray", size = 10) +
scale_shape_manual(values = c(1, 19)) +
theme_empty
```



::::

:::: {.column .fragment width="50%"}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
ggplot(data = pop_df, aes(x = x, y = y)) +
geom_abline(
  intercept = lm0$coefficients[1], slope = lm0$coefficients[2],
  color = red_pink, size = 3, alpha = 0.3
) +
geom_point(aes(shape = s2), color = "darkslategray", size = 6) +
geom_abline(
  intercept = lm1$coefficients[1], slope = lm1$coefficients[2],
  size = 2, linetype = 2, color = "black", alpha = 0.3
) +
geom_abline(
  intercept = lm2$coefficients[1], slope = lm2$coefficients[2],
  size = 2, linetype = 2, color = "black"
) +
scale_shape_manual(values = c(1, 19)) +
theme_empty
```

$\widehat{felicidad}_i = `r round(lm2$coefficients[1], 2)` + `r round(lm2$coefficients[2], 2)` galletas_i$


::::

:::::


## Regresi√≥n para la Muestra 3 {.medium}


$$ felicidad_i = `r round(lm0$coefficients[1], 2)` + `r round(lm0$coefficients[2], 2)` galletas_i + e_i $$

::::: {.columns}

:::: {.column width="50%"}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
ggplot(data = pop_df, aes(x = row, y = col, shape = s3)) +
geom_point(color = "darkslategray", size = 10) +
scale_shape_manual(values = c(1, 19)) +
theme_empty
```


::::

:::: {.column .fragment width="50%"}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
ggplot(data = pop_df, aes(x = x, y = y)) +
geom_abline(
  intercept = lm0$coefficients[1], slope = lm0$coefficients[2],
  color = red_pink, size = 3, alpha = 0.3
) +
geom_point(aes(shape = s3), color = "darkslategray", size = 6) +
geom_abline(
  intercept = lm1$coefficients[1], slope = lm1$coefficients[2],
  size = 2, linetype = 2, color = "black", alpha = 0.3
) +
geom_abline(
  intercept = lm2$coefficients[1], slope = lm2$coefficients[2],
  size = 2, linetype = 2, color = "black", alpha = 0.3
) +
geom_abline(
  intercept = lm3$coefficients[1], slope = lm3$coefficients[2],
  size = 2, linetype = 2, color = "black"
) +
scale_shape_manual(values = c(1, 19)) +
theme_empty
```


$\widehat{felicidad}_i = `r round(lm3$coefficients[1], 2)` + `r round(lm3$coefficients[2], 2)` galletas_i$


::::

:::::

## La incertidumbre importa! {.medium}

Como no sabemos si tenemos una buena o mala muestra, y queremos:

$$
\hat{\beta} \xrightarrow{\text{ü§û ojal√° ü§û}} \beta
$$

usamos $\hat{\beta}$ para acercarnos al verdadero efecto $\beta$.

. . .

[Por eso, utilizamos intervalos de confianza y pruebas de hip√≥tesis para cuantificar la incertidumbre en nuestras estimaciones]{.hl .hl-blue}



# Condiciones del modelo {#condic}

## Condiciones del modelo {.medium}

::: incremental

1. [Linealidad]{.hl .hl-blue}: hay una relaci√≥n lineal entre la variable dependiente y la variable explicativa

2. [Varianza Constante]{.hl .hl-blue}: la variabilidad de los errores es igual para todos los valores de la variable explicativa

3. [Normalidad]{.hl .hl-blue}: los errores siguen una distribuci√≥n normal

4. [Independencia]{.hl .hl-blue}: los errores son independientes entre ellos

:::


## ¬øC√≥mo graficar la variaci√≥n de los errores en R? {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: center


n_p <- 1000  # Define the number of observations

sim_norm <- tibble(
  i = 3,
  x = rnorm(n_p, mean = 5, sd = 1.5),
  e = rnorm(n_p, mean = 0, sd = 1),
  y = i + 0.5 * x + e,
)


ols_model <- lm(y ~ x, data=sim_norm)
```

```{r}
#| echo: true
#| eval: false
#| fig-align: center

ols_model <- lm(y ~ x, data=DATA)

augment(ols_model) |>
  ggplot(aes(x = .fitted, y = .resid)) +
  geom_point() +
  labs(x = "Valores predichos", y = "Errores") +
  theme_minimal()
```

## ¬øSon lineales los Errores? {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: center



augment(ols_model) |>
  ggplot(aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept=0, color="darkred", size=1.2)+
  labs(x = "Valores predichos", y = "Errores") +
  theme_minimal()
```

‚úÖLos errores no siguen un patr√≥n o estructura clara. Parecen aleatoriamente distribuidos


## ‚ùå  Claro patr√≥n en los Errores {.medium}


```{r}
#| echo: false
#| eval: true
#| fig-align: center

set.seed(123)

n_p <- 1000  # Define the number of observations

sim_quad <- tibble(
  i = 3,
  x = rnorm(n_p, mean = 5, sd = 1.5),
  e = rnorm(n_p, mean = 0, sd = 1) + 0.5 * (x - mean(x))^2,  # Quadratic term in error
  y = i + 0.5 * x + e
)

ols_model2 <- lm(y ~ x, data=sim_quad)


augment(ols_model2) |>
  ggplot(aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept=0, color="darkred", size=1.2)+
  labs(x = "Valores predichos", y = "Errores") +
  theme_minimal()
```



## ¬øLa varianza de los errores es constante? {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: center



augment(ols_model) |>
  ggplot(aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept=0, color="darkred", size=1.2)+
  geom_hline(yintercept=-2, color="orange", size=1.2, linetype ="dashed")+
  geom_hline(yintercept=2, color="orange", size=1.2, linetype ="dashed")+
  labs(x = "Valores predichos", y = "Errores") +
  theme_minimal()
```

‚úÖLa dispersi√≥n vertical de los errores es relativamente constante en la gr√°fica


## ‚ùå La varianza no es constante  {.medium}


```{r}
#| echo: false
#| eval: true
#| fig-align: center



n_p <- 1000  # Define the number of observations

sim_norm <- tibble(
  x = rnorm(n_p, mean = 4, sd = 1.5),  # Centered around 4
  e = rnorm(n_p, mean = 0, sd = x),  # Error increases with x
  y = 2 + 0.5 * x + e
)


ols_model <- lm(y ~ x, data=sim_norm)


augment(ols_model) |>
  ggplot(aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept=0, color="darkred", size=1.2)+
  geom_hline(yintercept=-5, color="orange", size=1.2, linetype ="dashed")+
  geom_hline(yintercept=5, color="orange", size=1.2, linetype ="dashed")+
  labs(x = "Valores predichos", y = "Errores") +
  theme_minimal()
```


## ¬øLos errores se distribuyen normalmente? {.medium}


```{r}
#| echo: false
#| eval: true
#| fig-align: center

augment(ols_model) |>
  ggplot(aes(x = .resid)) +
  geom_histogram(fill="lightblue", color="darkblue") +
  labs(title = "Distribuci√≥n de los Errores",
       x = "Errores",
       y = "Frecuencia") +
  theme_minimal()
```

‚úÖLa distribuci√≥n de los errores se parece a una distribuci√≥n normal



## ‚ùå  Los errores no se distribuyen como una normal

```{r}
#| echo: false
#| eval: true
#| fig-align: center

n <- 1000
x <- rnorm(n, mean = 5, sd = 2)
y <- 3 + 2 * x + rchisq(n, df = 3)  # Skewed residuals from chi-square

ols_model_h <- lm(y ~ x)

augment(ols_model_h) |> 
  ggplot(aes(x = .resid)) +
  geom_histogram(fill = "lightblue", color = "darkblue", bins = 30) +
  labs(title = "Distribuci√≥n de los Errores (Sesgados)",
       x = "Errores",
       y = "Frecuencia") +
  theme_minimal()
```


## ¬øC√≥mo graficar la distribuci√≥n de los errores en R? {.medium}

```{r}
#| echo: true
#| eval: false
#| fig-align: center

augment(ols_model) |> 
  ggplot(aes(x = .resid)) +
  geom_histogram(fill = "lightblue", color = "darkblue", bins = 30) +
  labs(title = "Distribuci√≥n de los Errores",
       x = "Errores",
       y = "Frecuencia") +
  theme_minimal()
```

## Independencia {.medium}

::: incremental


- Podemos verificar el supuesto de independencia a menudo bas√°ndonos en el contexto de los datos y en c√≥mo se recolectaron las observaciones.

- Si los datos se recolectaron en un orden particular, examina un diagrama de dispersi√≥n de los errores versus el orden en que se recolectaron los datos.

:::




## En la pr√°ctica.. {.medium}

Al verificar las condiciones del modelo, preguntense si alguna desviaci√≥n de estas condiciones es tan grande que:

1. Se deba proponer un modelo diferente.

2. Las conclusiones extra√≠das del modelo deban usarse con precauci√≥n.


:::{.fragment}
Si no es as√≠, las condiciones se cumplen suficientemente y podemos proceder con el modelo actual.
:::


## ¬øQu√© tan bueno es el modelo? {.medium}

### El R cuadrado

El $R^2$ es el porcentaje de la varianza de la variable dependiente explicada por el modelo de regresi√≥n

$$R^2=Corr(x,y)^2=Corr(y,\hat{y})$$

- Est√° entre 0 (nuestro modelo no predice nada) y 1 (predicci√≥n perfecta)

- No tiene unidad de medida



## ¬øQu√© tan bueno es el modelo? {.medium}

```{r}
#| echo: false
hollywood <- read_excel("hollywood_data.xlsx", sheet = "Sheet1")
```

Con la funci√≥n `glance()` podemos ver diferentes aspectos que eval√∫an el modelo:

```{r}
#| echo: true
hollywood_model <- lm(us_gross ~ opening_gross + budget + sequel, data=hollywood)
glance(hollywood_model)
```

:::{.fragment}

seg√∫n la primera columna, este modelo de regresi√≥n:

$$
\widehat{\text{US Gross}} = \hat{\beta_0} + \hat{\beta_1} \text{Opening Gross} + \hat{\beta_2} \text{Budget} + \hat{\beta_3} \text{Sequel}
$$

explica el 79% de la varianza del recaudo total en US

:::

## üí™ Ejercicio 1  {.medium}

1. Usando los datos `hollywood_data.xlsx`, eval√∫en si los errores del siquiente modelo de regresi√≥n son lineales, su varianza es constante y si se distribuyen normalmente:

$$\widehat{\text{US Total Gross}} = \hat{\beta_0} + \hat{\beta_1} \times \text{Opening Gross}$$


2. ¬øCu√°l es el $R^2$ del modelo en el punto 1? 

3. Comparen el $R^2$ del punto 2 con el $R^2$ de la diapositiva anterior. ¬øCu√°l explica m√°s la varianza del recaudo total en US?¬øPor qu√© creen que es as√≠?





# Consideraciones adicionales para una Regresi√≥n {#regresion}


## Relaciones no lineales {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10
set.seed(123)

# Create a tibble with 50 observations
galletas <- tibble(
  galletas = 1:20,
  felicidad = 2 + 0.3 * galletas - 0.02 * galletas^2 + rnorm(20, mean = 0, sd = 0.5)  # Non-linear (inverted U-shape)
)


base_cookies <- ggplot(galletas, aes(x=galletas, y=felicidad)) + 
  geom_point(size = 3) +
  coord_cartesian(xlim = c(0, 20), ylim = c(-1, 5)) +
  scale_x_continuous(breaks = 0:20) +
  labs(x = "Galletas consumidas", y = "Nivel de Felicidad") +
  theme_minimal(base_size = 14) +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold"))

base_cookies
```


## Relaciones no lineales {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10

base_cookies +
  geom_smooth(method = "lm", color = "#0074D9", se = FALSE)
```



## Relaciones no lineales {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10

base_cookies +
  geom_smooth(method = "loess", color = "#0074D9", se = FALSE)
```


## Relaciones no lineales en R {.medium}

Para agregar el t√©rmino cuadr√°tico a la regresi√≥n, se incluye el t√©rmino `I(x^2)` en el c√≥digo: 

```{r}
#| echo: true
#| eval: true
#| fig-align: center
modelo_felicidad <- lm(felicidad ~ galletas + I(galletas^2), data = galletas)
tidy(modelo_felicidad, conf.int = TRUE)
```

. . .

Nuestro modelo estimado entonces es:

$$\widehat{Felicidad}=2+0.33\times Galletas-0.02 \times Galletas^2$$


## ¬øExiste la relaci√≥n cuadr√°tica que vemos en la gr√°fica? {.medium}

$$\widehat{Felicidad}=\hat{\beta_0}+\hat{\beta_1}\times Galletas +\hat{\beta_2}\times Galletas^2 $$


:::{.fragment}

Evaluamos con una prueba de hip√≥tesis:

$$H_0:\hat{\beta_2}=0$$
$$H_1: \hat{\beta_2} \neq 0$$
:::

## ¬øQu√© hacer con una observaci√≥n at√≠pica (outlier)? {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10
galletas <- tibble(
  felicidad = c(0.5, 2, 1, 2.5, 3, 1.5, 2, 2.5, 8, 3),
  galletas = 1:10
)

base_cookies <- ggplot(galletas, aes(x=galletas, y=felicidad)) + 
  geom_point(size = 3) +
  coord_cartesian(xlim = c(0, 10), ylim = c(0, 8)) +
  scale_x_continuous(breaks = 0:10) +
  labs(x = "Galletas consumidas", y = "Nivel de Felicidad") +
  theme_minimal(base_size = 14) +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold"))

base_cookies

```


## ¬øQu√© hacer con una observaci√≥n at√≠pica (outlier)? {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10

# Remove the outlier where felicidad == 8
galletas_no_outlier <- galletas %>% filter(felicidad != 8)

# Combine data with an indicator for whether it's with or without the outlier
galletas$group <- "Con outlier"
galletas_no_outlier$group <- "Sin outlier"

# Combine both datasets
combined_data <- bind_rows(galletas, galletas_no_outlier)

# Base plot
base_cookies <- ggplot(combined_data, aes(x = galletas, y = felicidad, group = group)) + 
  geom_point(size = 3) +
  coord_cartesian(xlim = c(0, 10), ylim = c(0, 8)) +
  scale_x_continuous(breaks = 0:10) +
  labs(x = "Galletas consumidas", y = "Nivel de Felicidad") +
  theme_minimal(base_size = 14) +
  theme(panel.grid.minor = element_blank(),
        plot.title = element_text(face = "bold"))

# Plot with legend for solid and dashed lines
base_cookies +
  geom_smooth(aes(color = group, linetype = group), method = "lm", se = FALSE) + 
  scale_color_manual(values = c("Con outlier" = "#0074D9", "Sin outlier" = "red")) +
  scale_linetype_manual(values = c("Con outlier" = "solid", "Sin outlier" = "dashed")) +
  labs(title = "",
       color = "Regresi√≥n", linetype = "Regresi√≥n")

```

. . .

Como se menciono antes, es importante analizar la causa de los valores at√≠picos antes de eliminarlos, ya que pueden contener informaci√≥n valiosa.

## Efecto interacci√≥n {.medium}

Hasta ahora hemos asumido que el efecto de una variable es independiente de otra:

$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + e
$$
El efecto del incremento en una unidad de $x_1$ en $y$, es siempre $\beta_1$ e independiente de $x_2$


. . . 

Por ejemplo:


$$\widehat{Felicidad}=\hat{\beta_0}+\hat{\beta_1}\times Galletas+\hat{\beta_2} \times Estudiante $$


## Efecto interacci√≥n {.medium}

Si pensamos que el efecto de $x_1$ depende del valor de $x_2$, entonces debemos agregar una tercera variable de interacci√≥n al modelo:

$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1x_2+ e
$$
El termino de interacci√≥n es $x_1x_2$

. . . 

Por ejemplo:


$$  
  \begin{aligned}
\widehat{Felicidad}=&\hat{\beta_0}+\hat{\beta_1}\times Galletas+\hat{\beta_2} \times Estudiante \\
  & + \hat{\beta_3}\times Galletas*Estudiante
\end{aligned}
$$


## Interacciones - An√°lisis Visual {.medium}

El modelo donde las galletas tienen el mismo efecto para <font color="#000080">profesores</font> y <font color="#8B0000">estudiantes</font>

```{r}
#| echo: false
# Set seed
set.seed(12345)
# Sample size
n <- 1e3
# Parameters
beta0 <- 20; beta1 <- 0.5; beta2 <- 10; beta3 <- 3
# Dataset
int_df <- tibble(
  male = sample(x = c(F, T), size = n, replace = T),
  school = runif(n, 3, 9) - 3 * male,
  pay = beta0 + beta1 * school + beta2 * male + rnorm(n, sd = 7) + beta3 * male * school
)
reg_noint <- lm(pay ~ school + male, int_df)
reg_int <- lm(pay ~ school + male + school:male, int_df)
```


```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10

ggplot(data = int_df, aes(x = school, y = pay)) +
geom_point(aes(color = male, shape = male), size = 2.5) +
geom_hline(yintercept = 0) +
geom_vline(xintercept = 0) +
geom_abline(
  intercept = reg_noint$coefficients[1] + reg_noint$coefficients[3],
  slope = reg_noint$coefficients[2],
  color = "darkred", size = 1, alpha = 0.8
) +
geom_abline(
  intercept = reg_noint$coefficients[1],
  slope = reg_noint$coefficients[2],
  color = "navy", size = 1, alpha = 0.8
) +
xlab("Galletas") +
ylab("Felicidad") +
theme_empty +
theme(
  axis.title = element_text(size = 18),
  plot.margin = structure(c(0, 0, 0.1, 0), unit = "lines", valid.unit = 3L, class = "unit"),
) +
scale_color_manual("", values = c("navy", "darkred"), labels = c("Female", "Male")) +
scale_shape_manual("", values = c(16, 1), labels = c("Female", "Male"))
```


## Interacciones - An√°lisis Visual {.medium}

El modelo donde el efecto de las galletas puede diferir para <font color="#000080">profesores</font> y <font color="#8B0000">estudiantes</font>


```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 10
#| 
ggplot(data = int_df, aes(x = school, y = pay)) +
geom_point(aes(color = male, shape = male), size = 2.5) +
geom_hline(yintercept = 0) +
geom_vline(xintercept = 0) +
geom_abline(
  intercept = reg_noint$coefficients[1] + reg_noint$coefficients[3],
  slope = reg_noint$coefficients[2],
  color = "darkred", size = 0.75, alpha = 0.2
) +
geom_abline(
  intercept = reg_noint$coefficients[1],
  slope = reg_noint$coefficients[2],
  color = "navy", size = 0.75, alpha = 0.2
) +
geom_abline(
  intercept = reg_int$coefficients[1] + reg_int$coefficients[3],
  slope = reg_int$coefficients[2] + reg_int$coefficients[4],
  color = "darkred", size = 1, alpha = 0.8
) +
geom_abline(
  intercept = reg_int$coefficients[1],
  slope = reg_int$coefficients[2],
  color = "navy", size = 1, alpha = 0.8
) +
xlab("Galletas") +
ylab("Felicidad") +
theme_empty +
theme(
  axis.title = element_text(size = 18),
  plot.margin = structure(c(0, 0, 0.1, 0), unit = "lines", valid.unit = 3L, class = "unit"),
) +
scale_color_manual("", values = c("navy", "darkred"), labels = c("Female", "Male")) +
scale_shape_manual("", values = c(16, 1), labels = c("Female", "Male"))
```


## üí™ Ejercicio 2  {.medium}

1. Usando los datos `hollywood_data.xlsx`, creen una variable `comedy` que sea igual a 1 si el g√©nero de la pel√≠cula es "Comedy" y 0 en caso contrario.

2. Algunos productores de Hollywood creen que los retornos al recaudo el d√≠a del estreno son m√°s altos para las pel√≠culas de comedia. Comprueben esto Estimando la siquiente regresi√≥n:

$$  
  \begin{aligned}
\widehat{\text{US Total Gross}}=&\hat{\beta_0} + \hat{\beta_1} \times \text{Opening Gross} + \hat{\beta_2} \times \text{Comedy} \\
  & + \hat{\beta_3}\times \text{Opening Gross}*\text{Comedy}
\end{aligned}
$$


¬øTienen raz√≥n los productores de Hollywood? (Pista: $\hat{\beta_3}$ debe ser positivo y estad√≠sticamente diferente de 0)



# Transformaci√≥n Logar√≠tmica {#log}

## Transformaci√≥n logar√≠tmica {.medium}

Podemos considerar una transformaci√≥n logar√≠tmica de las variables de nuestro modelo (tanto variable dependiente e independientes) cuando:

::: incremental

- Exista una relaci√≥n no-lineal (exponencial) entre la variable dependiente y la explicativa.

- Alguna de las variables tenga una distribuci√≥n sesgada (muy distinta a la normal).
:::


## ¬øEs la distribuci√≥n del recaudo normal? {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 9

ggplot(data = hollywood, aes(x = us_gross/1000000)) +
    geom_density() +
    labs(
        x = "US Gross (in millions)",
    ) +
    theme_minimal()
```


## ¬øEs la distribuci√≥n del logaritmo del recaudo normal? {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 9
ggplot(data = hollywood, aes(x = log(us_gross/1000000))) +
    geom_density() +
    labs(
        x = "log(US Gross (in millions))",
    ) +
    theme_minimal()
```

::: {.absolute top="10%" left="5%" width="450px" .textbox .fragment .fade-up style="font-size:1.7rem;padding:0.5rem 1rem;" .altlist}
En este caso, la variable *us_gross* se distribuye log-normal
:::


## Transformaci√≥n logar√≠tmica {.medium}


```{r}
#| echo: true
#| eval: true

hollywood_model <- lm(us_gross ~ opening_gross, data=hollywood)
tidy(hollywood_model, conf.int = TRUE)
```

La regresi√≥n lineal estimada es:

$$\widehat{\text{US Total Gross}} = 5,108,220 + 3.12 \times \text{Opening Gross}$$


## Transformaci√≥n logar√≠tmica {.medium}

¬øC√≥mo cambian los resultados si estimamos una regresi√≥n con ambias variables como logar√≠tmos?

```{r}
#| echo: true
#| eval: true
hollywood <- hollywood |> 
  mutate(log_opening_gross=log(opening_gross),
         log_us_gross=log(us_gross))

hollywood_model_logs <- lm(log_us_gross ~ log_opening_gross, data=hollywood)
tidy(hollywood_model_logs, conf.int = TRUE)
```


La regresi√≥n lineal estimada es:


$$\widehat{\text{log(US Total Gross})} = 1.58 + 0.97 \times \text{log(Opening Gross)}$$



## Regresi√≥n Nivel-Nivel {.medium}

$$y=\beta_0+\beta_1x+e$$
Interpretaci√≥n: un cambio de una unidad en $x$, est√° asociado a un cambio en $\beta_1$ unidades en $y$.

## Regresi√≥n Nivel-Log {.medium}

$$y=\beta_0+\beta_1log(x)+e$$
Interpretaci√≥n: un aumento de 1% en $x$, es asociado a un cambio en $\beta_1/100$ unidades a $y$.

## Regresi√≥n Log-Nivel {.medium}

$$log(y)=\beta_0+\beta_1x+e$$
Interpretaci√≥n: un incremento de una unidad en $x$, est√° asociado a un cambio de $(\beta_1\times 100)\%$ en $y$.

## Regresi√≥n Log-Log {.medium}

$$log(y)=\beta_0+\beta_1log(x)+e$$
Interpretaci√≥n: un aumento de 1% en $x$, est√° asociado a un cambio de $\beta_1\%$  en $y$.