---
title: Analítica de los Negocios
author: Carlos Cardona Andrade
subtitle: Pruebas de Hipótesis II
execute:
  freeze: auto
  echo: true
  fig-width: 6
  fig-height: 5
format:
  revealjs: 
   theme: ../slides.scss
   header-includes: |
      <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" rel="stylesheet"/>
   slide-number: true
   show-slide-number: all
   transition: fade
   progress: true
   multiplex: false
   scrollable: false
   preview-links: false
   hide-inactive-cursor: true
   highlight-style: printing
   pause: true
---
     
## ¿Qué deberían saber para el parcial? {.medium}

1. Cargar un archivo y un paquete en R

2. Los verbos del paquete `tidyverse`: filter, select, arrange, mutate, summarise

3. Describir una distribución (medidas de tendencia central, dispersión)

4. Interpretar una correlación

5. Calcular probabilidades bajo la curva normal

6. ¿Qué es un intervalo de confianza?¿Qué es el nivel de confianza?

7. ¿Qué es una prueba de hipótesis? 

    - ¿Cómo se rechaza?
    - ¿Qué implicaciones tiene rechazar o no rechazar?


## Plan para hoy

1. [La Distribución $t$](#tdist)

2. [Consideraciones al elaborar pruebas de hipótesis](#consider)

3. [Algunas ideas incorrectas sobre la prueba de hipótesis](#ideasmal)


# La Distribución $t$ {#tdist}


## William Gosset {.medium}

![](img/guinness.jpg){height="400" fig-align="center"}


## Recordemos el TLC {.medium}

$$\bar{x}\sim N(\mu,\dfrac{\sigma}{\sqrt{n}})$$

Esto significa que:

$$Z=\dfrac{\bar{x}-\mu}{\dfrac{\sigma}{\sqrt{n}}}\sim N(0,1)$$

. . .


Como habíamos mencionado antes, el problema radica en que ${\color{orange} \sigma}$ usualmente es desconocida para nosotros...


## ¿Qué pasa si $\sigma$ es desconocida? {.medium}

En la práctica, nunca conocemos el valor verdadero de ${\color{orange} \sigma}$, por lo que lo estimamos a partir de nuestros datos con ${\color{orange} s}$

Podemos construir el siguiente estadístico de prueba para contrastar la media poblacional de una sola muestra, la cual sigue una distribución $t$ con $n−1$ grados de libertad:

$$t=\dfrac{\bar{x}-\mu}{\dfrac{{\color{orange} s}}{\sqrt{n}}}\sim t_{n-1}$$

## La distribución $t$ {.medium}

- La distribución $t$ también es unimodal y simétrica, y está centrada en 0

- Tiene colas más gruesas que la distribución normal

- Esto compensa la variabilidad adicional introducida al usar ${\color{orange} s}$ en lugar de $\sigma$ en el cálculo del error estándar (SE)

- Está definida por los grados de libertad $n-1$


## Dist. Normal vs Dist. $t$ {.medium}

```{r}
#| echo: false
#| fig-align: center
#| fig-width: 8
library(tidyverse)

# Define x-axis range
x <- seq(-4, 4, length = 1000)

# Define t-distributions with different degrees of freedom
df_values <- c(1, 3, 8, 20)
t_distributions <- lapply(df_values, function(df) data.frame(x = x, y = dt(x, df), df = paste(df, "df")))

# Standard normal distribution
normal_dist <- data.frame(x = x, y = dnorm(x), df = "Standard Normal")

# Combine data
df_plot <- bind_rows(t_distributions, normal_dist)


# Convert 'df' column to factor with the desired order
df_plot$df <- factor(df_plot$df, levels = c("1 df", "3 df", "8 df", "20 df", "Standard Normal"))


# Define colors for the distributions
colors <- c("1 df" = "purple", "3 df" = "blue", "8 df" = "red", "20 df" = "green", "Standard Normal" = "black")

# Create the plot
ggplot(df_plot, aes(x = x, y = y, color = df)) +
  geom_line(size = 1) +
  scale_color_manual(values = colors) +
  labs(x = "t-value (# standard deviations from the mean)", 
       y = "Probability",
       color = "") +
  theme_minimal() +
  theme(
    legend.position = "right",
    legend.text = element_text(size = 12),
    axis.text = element_text(size = 14)
  )
```


## Distribución $t$ en R {.medium}

::: {.columns}
::: {.column width=50%}
¿Cómo encontrar probabilidades?
```{r}
#| echo: true
#| eval: true
#P(t < -1.96)
pt(-1.96, df = 9)
```


```{r}
#| echo: true
#| eval: true
#P(t > -1.96)
pt(-1.96, df = 9, 
   lower.tail = FALSE)
```
:::

::: {.column .fragment width=50%}
¿Cómo encontrar valores críticos?
```{r}
#| echo: true
#| eval: true
# Encontrando Q1
qt(0.25, df = 9)
```


```{r}
#| echo: true
#| eval: true
# Q3
qt(0.75, df = 9)
```

:::
:::


## Dist. Normal vs Dist. $t$ (valores críticos) {.medium}

::: {.columns}
::: {.column width=50%}

```{r}
#| echo: true
#| eval: true
qnorm(0.975)
```


```{r}
#| echo: false
#| eval: true

# Define the x-axis range and normal distribution
x <- seq(-4, 4, length = 1000)
y <- dnorm(x)

# Create a data frame
df <- data.frame(x = x, y = y)

# Plot the normal distribution with highlighted regions
ggplot(df, aes(x = x, y = y)) +
  geom_area(aes(x = ifelse(x >= -1.96 & x <= 1.96, x, NA)), fill = "yellow", alpha = 0.5) +
  geom_area(aes(x = ifelse(x < -1.96, x, NA)), fill = "darkred", alpha = 0.5) +
  geom_area(aes(x = ifelse(x > 1.96, x, NA)), fill = "darkred", alpha = 0.5) +
  geom_line(color = "black", size = 1) +
  scale_x_continuous(breaks = c(-1.96, 1.96),
                         labels = c(expression(Z^{"*"}==-1.96), expression(Z^{"*"}==1.96))) +
  labs(x = "", y= "") +
  theme_minimal() +
  theme(
    legend.position = "none",
    axis.text = element_text(size = 14),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank())

```



:::

::: {.column .fragment width=50%}

```{r}
#| echo: true
#| eval: true
qt(0.975, df = 9)
```


```{r}
#| echo: false
#| eval: true
# Define the x-axis range
x <- seq(-4, 4, length = 1000)
y <- dt(x, df = 9)  # t-distribution with df = 9

# Create a data frame
df <- data.frame(x = x, y = y)

# Critical value for df = 9 at α = 0.05 (two-tailed test)
critical_value <- 2.26

# Plot the t-distribution with highlighted regions
ggplot(df, aes(x = x, y = y)) +
  geom_area(aes(x = ifelse(x >= -critical_value & x <= critical_value, x, NA)), fill = "yellow", alpha = 0.5) +
  geom_area(aes(x = ifelse(x < -critical_value, x, NA)), fill = "darkred", alpha = 0.5) +
  geom_area(aes(x = ifelse(x > critical_value, x, NA)), fill = "darkred", alpha = 0.5) +
  geom_line(color = "black", size = 1) +
  scale_x_continuous(breaks = c(-critical_value, critical_value),
                     labels = c(expression(t^{"*"}==-2.26), expression(t^{"*"}==2.26))) +
  labs(x = "", y = "") +
  theme_minimal() +
  theme(
    legend.position = "none",
    axis.text = element_text(size = 14),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
  )
```

:::
:::


## Ejemplo: Rendimiento de un bono {.medium}

Una empresa de gestión de activos recientemente cambió al gerente del fondo que administra un bono de alto rendimiento. Se espera que este cambio tenga un impacto positivo en los retornos del bono. Para evaluar si el cambio de manager ha mejorado significativamente los retornos del bono, se recogieron los retornos mensuales del bono durante 10 meses antes y 10 meses después del cambio de manager.

  $$H_0:\mu_D-\mu_A=0$$
  
  $$H_A:\mu_D-\mu_A\neq0$$
    
Nuestra hipótesis nula es que no existe ningún cambio en el rendimiento promedio del bono con el cambio de gerente ($\mu_D=\mu_A$).
    
## Ejemplo: Rendimiento de un bono {.medium}

```{r}
#| echo: true
#| eval: true

# Retornos del bono antes del cambio de gerente
antes <-c(200.1, 190.9, 192.7, 213, 241.4, 196.9, 172.2, 185.5, 205.2, 193.7)
# Retornos del bono después del cambio de gerente
despues <-c(392.9, 393.2, 345.1, 393, 434, 427.9, 422, 383.9, 392.3, 352.2)
# Creamos el data frame
bono <- tibble( 
                grupo = rep(c("antes", "despues"), each = 10),
                retorno = c(antes,  despues)
                )
bono
```


## Ejemplo: Rendimiento de un bono - Gráfica {.medium}

```{r}
#| fig.align: 'center'
#| echo: false
#| eval: true

# Retornos del bono antes del cambio de manager
library(ggpubr)
ggboxplot(bono, x = "grupo", y = "retorno", 
          color = "grupo", palette = c("navy", "darkred"),
          order = c("antes", "despues"),
          ylab = "Retorno", xlab = "Grupos")

```



## Ejemplo: Rendimiento de un bono - t.test() {.medium}

```{r}
#| fig.align: 'center'
#| echo: true
#| eval: true

# Calculemos el test
test_resultado <- t.test(retorno ~ grupo, data = bono, conf.level=0.95)
test_resultado

```

. . .


¿Cuál es el valor crítico $t^*$?

```{r}
#| echo: true
#| eval: true
qt(0.975, df = 15)
```

## Ejemplo - Decisión basada en el estadístico $t$ {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 8
# Define the x-axis range
x <- seq(-4, 4, length = 1000)
y <- dt(x, df = 15)  # t-distribution with df = 20

# Create a data frame
df <- data.frame(x = x, y = y)

# Critical value for df = 20 at α = 0.05 (two-tailed test)
critical_value <- qt(0.975, df = 15)  # ≈ 2.086

# Plot the t-distribution with highlighted regions
ggplot(df, aes(x = x, y = y)) +
  geom_area(aes(x = ifelse(x >= -critical_value & x <= critical_value, x, NA)), 
            fill = "white", alpha = 0.5) +
  geom_area(aes(x = ifelse(x < -critical_value, x, NA)), fill = "darkred", alpha = 0.5) +
  geom_area(aes(x = ifelse(x > critical_value, x, NA)), fill = "darkred", alpha = 0.5) +
  geom_line(color = "black", size = 1) +
  geom_vline(xintercept = -17, linetype = "dashed", color = "darkblue", size = 1) +  # Dashed line at t = -17
  scale_x_continuous(breaks = c(-critical_value, critical_value, -17),
                     labels = c(expression(t^{"*"}==-2.13), 
                                expression(t^{"*"}==2.13), 
                                expression(t[prueba]==-17.71))) +
  labs(x = "", y = "") +
  theme_minimal() +
  theme(
    legend.position = "none",
    axis.text = element_text(size = 14),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
  )
```

Rechazamos $H_0$ porque $t<t^*_{\alpha=0.05}$

## Ejemplo - Decisión basada en el IC {.medium}

```{r}
#| echo: false
#| eval: true
#| fig-align: center
# Perform the t-test
test_resultado <- t.test(retorno ~ grupo, data = bono)

# Extract confidence interval and mean difference
ci_lower <- test_resultado$conf.int[1]
ci_upper <- test_resultado$conf.int[2]
mean_diff <- test_resultado$estimate[2] - test_resultado$estimate[1]  # Mean difference

# Create a data frame for plotting
ci_data <- data.frame(
  Mean = mean_diff,
  Lower = ci_lower,
  Upper = ci_upper,
  Level = "95% CI"
)

# Plot confidence interval
ggplot(ci_data, aes(x = Level, y = Mean)) +
  geom_linerange(aes(ymin = Lower, ymax = Upper, color = Level), size = 1.5, color="darkgreen") +  # Confidence interval
  geom_point(aes(y = Lower), size = 3, color="darkgreen") +  # Lower bound
  geom_point(aes(y = Upper), size = 3, color="darkgreen") +  # Upper bound
  geom_hline(yintercept = 0, linetype = "dashed", color = "darkred", size = 1) +  # Dashed line at 0
  labs(y = "Difference in Mean Returns", x = "", title = "95% Confidence Interval for Mean Difference") +
  theme_minimal() + ylim(-250, 150) +
  theme(legend.position = "none", axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Rechazamos la $H_0$ porque el IC no incluye el 0

## Ejemplo - Decisión basada en el p-value {.medium}

$$¿p<\alpha?$$

```{r}
#| echo: true
#| eval: true
# p-value
test_resultado$p.value<0.05
```

Rechazamos porque $p<\alpha=0.05$

# Consideraciones al elaborar pruebas de hipótesis {#consider}

## Consecuencias de los errores Tipo I y II {.medium}

Los errores de tipo I y tipo II son diferentes tipos de equivocaciones y tienen consecuencias distintas:

:::incremental

- $H_0$ representa el **status quo**, lo que generalmente creemos cierto

- No rechazar $H_0$ significa que el status quo se mantiene

- Rechazar $H_0$ indica que se refuta algo previamente creído, como un avance científico o una nueva estrategia de inversión

- Un error de tipo I puede llevar a conclusiones falsas y desperdicio de recursos hasta que se invalide el hallazgo

:::


## Consecuencias de los errores Tipo I y II {.medium}

Un error de tipo II (no reconocer un avance científico o una nueva estrategia financiera) representa una oportunidad perdida para el progreso científico o para la empresa.

:::incremental

- Los errores de tipo II también pueden ser costosos, pero generalmente pasan desapercibidos

- Por eso, es más importante controlar la tasa de error de tipo I que la tasa de error de tipo II

:::


## ¿Cuál es la probabilidad del error Tipo I? {.medium}

¿Cuál es la probabilidad de rechazar $H_0$?

```{r}
#| fig.align: 'center'
#| echo: false
#| eval: true

# Define the x-axis range and normal distribution
x <- seq(-4, 4, length = 1000)
y <- dnorm(x)

# Create a data frame
df <- data.frame(x = x, y = y)

# Plot the normal distribution with highlighted regions
ggplot(df, aes(x = x, y = y)) +
  geom_area(aes(x = ifelse(x >= -1.96 & x <= 1.96, x, NA)), fill = "white", alpha = 0.5) +
  geom_area(aes(x = ifelse(x < -1.96, x, NA)), fill = "darkgreen", alpha = 0.5) +
  geom_area(aes(x = ifelse(x > 1.96, x, NA)), fill = "darkgreen", alpha = 0.5) +
  geom_line(color = "black", size = 1) +
  scale_x_continuous(breaks = c(0),
                         labels = c(expression(H[0]:mu==mu[0]))
) +
  labs(x = "", y= "") +
  theme_minimal() +
  theme(
    legend.position = "none",
    axis.text = element_text(size = 14),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank())

```

. . .

<center>
Es ${\color{green} \alpha}$!
<center>

## Nivel de significancia = p(Error Tipo I) {.medium}

Esto significa que, si $H_0$ es verdadera, solo hay un $(100\times\alpha)$% de cometer el error Tipo I!


$$\color{green}{P(\text{Error de tipo I} \mid H_0 \text{ verdadera}) = \alpha}$$


- Por eso preferimos valores pequeños de $\alpha$ — aumentar $\alpha$ incrementa la tasa de error de tipo I

- Sin embargo, el nivel de significancia no controla la tasa de error de tipo II


## Reportando el p-value {.medium}

No se limiten a reportar la conclusión de si se rechaza $H_0$. Muestren el p-value.

:::incremental


- Un p-value de 0.04 y un p-value de 0.000001 no son lo mismo. Aunque $H_0$ se rechace en ambos casos, la fuerza de la evidencia es muy diferente

- Concluir simplemente si $H_0$ es rechazada sin el p-value es como concluir que la temperatura es "fría" o "caliente"

- Es mucho mejor reportar el p-value y permitir que la gente elija su propio nivel de significancia. Es similar a decirle a alguien la temperatura y dejar que decida cómo interpretarla

:::

## Reportando el p-value:¿Cuál gerente preferirían? {.medium}


```{r}
#| echo: false
#| eval: true
#| fig-align: center
#| fig-width: 8
# Define the x-axis range
x <- seq(-4, 4, length = 1000)
y <- dt(x, df = 15)  # t-distribution with df = 20

# Create a data frame
df <- data.frame(x = x, y = y)

# Critical value for df = 20 at α = 0.05 (two-tailed test)
critical_value <- qt(0.975, df = 15)  # ≈ 2.086

# Plot the t-distribution with highlighted regions
ggplot(df, aes(x = x, y = y)) +
  geom_area(aes(x = ifelse(x >= -critical_value & x <= critical_value, x, NA)), 
            fill = "white", alpha = 0.5) +
  geom_area(aes(x = ifelse(x < -critical_value, x, NA)), fill = "darkred", alpha = 0.5) +
  geom_area(aes(x = ifelse(x > critical_value, x, NA)), fill = "darkred", alpha = 0.5) +
  geom_line(color = "black", size = 1) +
  geom_vline(xintercept = -17, linetype = "dashed", color = "darkblue", size = 1) +
  geom_vline(xintercept = -2.2, linetype = "dashed", color = "darkblue", size = 1) +
  scale_x_continuous(breaks = c(-17, -2.2),
                     labels = c(expression(p[1] == 9 %*% 10^-12), 
                                expression(p[2] == 0.02))) +
  labs(x = "", y = "") +
  theme_minimal() +
  theme(
    legend.position = "none",
    axis.text = element_text(size = 14),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
  )
```


# Algunas ideas incorrectas sobre la prueba de hipótesis {#ideasmal}

## El método científico: prueba y refutación {.medium}

- Hay una verdad sutil pero fundamental en el método científico, y es que nunca se puede realmente probar una hipótesis con él, solo `refutar` la hipótesis

- En palabras de Albert Einstein:

> "No amount of experimentation can ever prove me right; a single experiment can prove me wrong."

- Por lo tanto, nunca decimos que la hipótesis nula es verdadera

- Cuando la evidencia no es lo suficientemente fuerte como para rechazar la nula, no decimos "aceptamos la hipótesis nula", sino que decimos "no podemos rechazar la hipótesis nula"


## Fallar al rechazar $H_0$ no prueba que $H_0$ sea cierta {.medium}

Un error común es concluir a partir de un p-value alto que la $H_0$ es probablemente verdadera.

:::incremental
- **p-value bajo**: evidencia en contra de $H_0$

- **p-value alto**: no podemos concluir que $H_0$ es verdadera; podríamos cometer un error de tipo II

- La tasa de error de tipo II es mayor que la de tipo I, que se controla.

- Cuando no rechazamos $H_0$, a menudo significa que los datos no son capaces de distinguir entre $H_0$ y $H_A$ (porque los datos son demasiado ruidosos, etc.).
:::

## Ejemplo: Dietas y cáncer {.medium}

::: incremental

- Women’s Health Initiative encontró que las dietas bajas en grasa reducen el riesgo de cáncer de seno con un p-value de **0.07**

- El titular del New York Times: ["Estudio encuentra que las dietas bajas en grasa no detendrán el cáncer"](https://www.nytimes.com/2006/02/07/health/study-finds-lowfat-diet-wont-stop-cancer-or-heart-disease.html){target="_blank"}

- El editorial principal afirmó que el estudio presentaba "evidencia sólida de que la guerra contra las grasas fue en vano" y añadió "este es el fin para la creencia de que reducir el porcentaje de grasa total en la dieta es importante para la salud"

- No encontrar evidencia del efecto no significa que las dietas bajas en grasa no tengan ningún efecto

:::

## No tomen la significancia al 0.05 demasiado enserio {.medium}

::: incremental

- Un p-value de 0.049 y un p-value de 0.051 ofrecen casi la misma evidencia contra $H_0$

- Por ejemplo, un estudio famoso de 2009 sobre una vacuna que podría proteger contra el VIH reportó un p-value a dos colas de 0.08, mientras que el p-value a una cola fue 0.04

- Se desató mucho debate y controversia, en parte porque las dos formas de analizar los datos producen p-values a ambos lados de 0.05

- Gran parte de este debate y controversia es bastante inútil; ambos p-values te dicen esencialmente lo mismo: que la vacuna tiene potencial, pero que los resultados aún no son concluyentes

:::

## Las pruebas de hipótesis no pueden decirnos... {.medium}

- si el diseño de un estudio está defectuoso
- si los datos se han recolectado adecuadamente

. . .

Por lo tanto, no podemos concluir a partir de un p-value pequeño si la conclusión se puede generalizar a una población más grande

$$\text{Garbage In} \rightarrow \text{Garbage Out}$$

## Significancia estadística no significa importancia práctica {.medium}

Otro error es leer demasiado en el término **estadísticamente significativo**.

:::incremental

- Decir que los resultados son estadísticamente significativos informa al lector que los hallazgos son poco probables de ser resultado del azar.

- Sin embargo, no dice nada sobre la importancia práctica del hallazgo.

- E.g., rechazar $H_0: \mu_1=\mu_2$ solo nos dice que $\mu_1\neq\mu_2$, pero no qué tan grande o importante es $\mu_1-\mu_2$. Puede ser que la diferencia no sea relevante por ser muy pequeña a pesar de ser significativa.

- Solución: `Reporten un intervalo de confianza` del parámetro para que la gente pueda decidir si la diferencia es lo suficientemente grande como para ser relevante.

:::


## Ejemplo: ¿Cuál es la diferencia de calidad entre el café colombiano y el resto? {.medium}

$$H_0:\mu_{\text{Colombia}} -\mu_{\text{No Colombia}}=0$$

```{r}
#| echo: false
setwd("C:/Users/ccard/OneDrive/Documentos/GitHub/analitica_2025/data/coffee")
coffee_data <- read.csv("coffee_ratings.csv")
coffee_data <- coffee_data |>
  filter(total_cup_points>50)
coffee_data <- coffee_data |>
  mutate(colombia=ifelse(country_of_origin =="Colombia", TRUE,FALSE))
t.test(total_cup_points ~ colombia, coffee_data, conf.level=0.95)
```

En este caso, rechazamos la $H_0$ de que sean iguales pero, ¿es la diferencia de calidad considerable?

## En resumen... {.medium}

- Rechazar $H_0$ no significa que estamos 100% seguros que $H_0$ es falsa

- El p-value no es la probabilidad de que $H_0$ sea verdadera.

- No tomen el nivel de significancia de 0.05 demasiado en serio.

- Las pruebas de hipótesis no pueden decirnos si los datos se recolectaron adecuadamente o si el diseño de un estudio es malo.

- La significancia estadística no se traduce en importancia práctica
